{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d7d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as torch_transforms\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../../\")\n",
    "\n",
    "from modules.dvae.model import DVAE\n",
    "from modules.common_utils import latent_to_img\n",
    "from datasets.mnist_loader import MNISTData\n",
    "from notebooks.utils import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "134ec151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(clf, testloader, device):\n",
    "    clf.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in testloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            outputs = clf(img)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d733e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "from modules.common_blocks import TrEncoderBlock\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_height,\n",
    "                 img_width,\n",
    "                 img_channels,\n",
    "                 patch_height,\n",
    "                 patch_width,\n",
    "                 embed_dim,\n",
    "                 num_blocks,\n",
    "                 hidden_dim,\n",
    "                 n_attn_heads,\n",
    "                 dropout_prob,\n",
    "                 out_dim,\n",
    "                 sigmoid_output=False,\n",
    "                 device=torch.device('cpu')):\n",
    "        super(ViT, self).__init__()\n",
    "        self.device = device\n",
    "        self.sigmoid_output = sigmoid_output\n",
    "\n",
    "        self.n_h_patch = img_height // patch_height\n",
    "        self.n_w_patch = img_width // patch_width\n",
    "        patch_dim = img_channels * patch_height * patch_width\n",
    "\n",
    "        self.img_pe_col = nn.Parameter(torch.randn(self.n_h_patch, 1, embed_dim))\n",
    "        self.img_pe_row = nn.Parameter(torch.randn(self.n_w_patch, 1, embed_dim))\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Linear(patch_dim, embed_dim),\n",
    "        )\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "\n",
    "        self.tr_encoder_blocks = nn.ModuleList([\n",
    "            TrEncoderBlock(n_features=embed_dim,\n",
    "                           n_attn_heads=n_attn_heads,\n",
    "                           n_hidden=hidden_dim,\n",
    "                           dropout_prob=dropout_prob,\n",
    "                           norm_first=True)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, out_dim),\n",
    "        )\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x, average_cls_token=False):\n",
    "        batch, ch, h, w = x.size()\n",
    "\n",
    "        x = self.to_patch_embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        pe_column = self.img_pe_col.repeat(self.n_w_patch, batch, 1)\n",
    "        pe_row = self.img_pe_row.repeat_interleave(self.n_h_patch, dim=0).repeat(1, batch, 1)\n",
    "        x = x + pe_column + pe_row\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand(-1, batch, -1)\n",
    "        \n",
    "        full_x = torch.cat([cls_tokens, x], dim=0)\n",
    "        for i, block in enumerate(self.tr_encoder_blocks):\n",
    "            full_x = block(full_x)\n",
    "        \n",
    "        if average_cls_token:\n",
    "            cls_input = full_x.mean(dim=0)\n",
    "        else:\n",
    "            cls_input = full_x[0, :, :]\n",
    "        \n",
    "        cls = self.mlp_head(cls_input).squeeze()\n",
    "\n",
    "        if self.sigmoid_output:\n",
    "            return torch.sigmoid(cls)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8ad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    img_height                  = 28\n",
    "    img_width                   = 28\n",
    "    img_channels                = 1\n",
    "    patch_height                = 4\n",
    "    patch_width                 = 4\n",
    "    embed_dim                   = 128\n",
    "    num_blocks                  = 8\n",
    "    hidden_dim                  = 256\n",
    "    n_attn_heads                = 8\n",
    "    dropout_prob                = 0.1\n",
    "    out_dim                     = 10\n",
    "    sigmoid_output              = False\n",
    "\n",
    "    dataset_type                = \"classic\"\n",
    "    root_img_path               = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/data/MNIST/\"\n",
    "    \n",
    "    NUM_EPOCHS                  = 20\n",
    "    BATCH_SIZE                  = 512\n",
    "    LR                          = 0.001\n",
    "\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4546650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = MNISTData(\n",
    "    img_type=CONFIG.dataset_type,\n",
    "    root_path=CONFIG.root_img_path,\n",
    "    batch_size=CONFIG.BATCH_SIZE)\n",
    "\n",
    "train_loader = data_source.get_train_loader()\n",
    "test_loader = data_source.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a0eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ViT(\n",
    "    img_height=CONFIG.img_height,\n",
    "    img_width=CONFIG.img_width,\n",
    "    img_channels=CONFIG.img_channels,\n",
    "    patch_height=CONFIG.patch_height,\n",
    "    patch_width=CONFIG.patch_width,\n",
    "    embed_dim=CONFIG.embed_dim,\n",
    "    num_blocks=CONFIG.num_blocks,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    n_attn_heads=CONFIG.n_attn_heads,\n",
    "    dropout_prob=CONFIG.dropout_prob,\n",
    "    out_dim=CONFIG.out_dim,\n",
    "    sigmoid_output=CONFIG.sigmoid_output,\n",
    "    device=CONFIG.DEVICE)\n",
    "\n",
    "clf.train()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b476d793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "Epoch: 0 Iteration: 0 Loss: 2.488192319869995\n",
      "Epoch: 0 Iteration: 50 Loss: 1.9112589359283447\n",
      "Epoch: 0 Iteration: 100 Loss: 0.4603889584541321\n",
      "Epoch: 1 Iteration: 150 Loss: 0.3399171233177185\n",
      "Epoch: 1 Iteration: 200 Loss: 0.2801797688007355\n",
      "Epoch: 2 Iteration: 250 Loss: 0.13375626504421234\n",
      "Epoch: 2 Iteration: 300 Loss: 0.21883732080459595\n",
      "Epoch: 2 Iteration: 350 Loss: 0.1882646232843399\n",
      "Epoch: 3 Iteration: 400 Loss: 0.099082350730896\n",
      "Epoch: 3 Iteration: 450 Loss: 0.1347513645887375\n",
      "Epoch: 4 Iteration: 500 Loss: 0.12107304483652115\n",
      "Epoch: 4 Iteration: 550 Loss: 0.07986947894096375\n",
      "Epoch: 5 Iteration: 600 Loss: 0.10484745353460312\n",
      "Epoch: 5 Iteration: 650 Loss: 0.07460377365350723\n",
      "Epoch: 5 Iteration: 700 Loss: 0.0954517349600792\n",
      "Epoch: 6 Iteration: 750 Loss: 0.10170673578977585\n",
      "Epoch: 6 Iteration: 800 Loss: 0.09940138459205627\n",
      "Epoch: 7 Iteration: 850 Loss: 0.08316060155630112\n",
      "Epoch: 7 Iteration: 900 Loss: 0.06859330832958221\n",
      "Epoch: 8 Iteration: 950 Loss: 0.1136760264635086\n",
      "Epoch: 8 Iteration: 1000 Loss: 0.06592745333909988\n",
      "Epoch: 8 Iteration: 1050 Loss: 0.07452687621116638\n",
      "Epoch: 9 Iteration: 1100 Loss: 0.06506656855344772\n",
      "Epoch: 9 Iteration: 1150 Loss: 0.06875649094581604\n",
      "Epoch: 10 Iteration: 1200 Loss: 0.07027105987071991\n",
      "Epoch: 10 Iteration: 1250 Loss: 0.034130439162254333\n",
      "Epoch: 11 Iteration: 1300 Loss: 0.025473952293395996\n",
      "Epoch: 11 Iteration: 1350 Loss: 0.04518566280603409\n",
      "Epoch: 11 Iteration: 1400 Loss: 0.06059650331735611\n",
      "Epoch: 12 Iteration: 1450 Loss: 0.04161874204874039\n",
      "Epoch: 12 Iteration: 1500 Loss: 0.08144686371088028\n",
      "Epoch: 13 Iteration: 1550 Loss: 0.06437072902917862\n",
      "Epoch: 13 Iteration: 1600 Loss: 0.07061684876680374\n",
      "Epoch: 13 Iteration: 1650 Loss: 0.036838334053754807\n",
      "Epoch: 14 Iteration: 1700 Loss: 0.05838119983673096\n",
      "Epoch: 14 Iteration: 1750 Loss: 0.030433977022767067\n",
      "Epoch: 15 Iteration: 1800 Loss: 0.0464601069688797\n",
      "Epoch: 15 Iteration: 1850 Loss: 0.023075591772794724\n",
      "Epoch: 16 Iteration: 1900 Loss: 0.038233011960983276\n",
      "Epoch: 16 Iteration: 1950 Loss: 0.03549203649163246\n",
      "Epoch: 16 Iteration: 2000 Loss: 0.04165134206414223\n",
      "Epoch: 17 Iteration: 2050 Loss: 0.02242601290345192\n",
      "Epoch: 17 Iteration: 2100 Loss: 0.031142311170697212\n",
      "Epoch: 18 Iteration: 2150 Loss: 0.03390922769904137\n",
      "Epoch: 18 Iteration: 2200 Loss: 0.029923133552074432\n",
      "Epoch: 19 Iteration: 2250 Loss: 0.049125365912914276\n",
      "Epoch: 19 Iteration: 2300 Loss: 0.027364417910575867\n",
      "Epoch: 19 Iteration: 2350 Loss: 0.05037304386496544\n"
     ]
    }
   ],
   "source": [
    "print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "iteration = 0\n",
    "for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "    for img, label in train_loader:\n",
    "        \n",
    "        label = label.to(CONFIG.DEVICE)\n",
    "        img = img.to(CONFIG.DEVICE)\n",
    "        \n",
    "        pred = clf(img)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if iteration % 50 == 0:\n",
    "            print(\"Epoch: {} Iteration: {} Loss: {}\".format(epoch, iteration, loss.item()))\n",
    "        \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4e1827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(clf, test_loader, CONFIG.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c163d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b141ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c06ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c8224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
