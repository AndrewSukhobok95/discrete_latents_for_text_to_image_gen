{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159420cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as torch_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ad6bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../../\")\n",
    "\n",
    "from modules.dvae.model import DVAE\n",
    "from modules.dvae.funcs import ng_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263a51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, figsize=(8, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888c7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    img_channels                = 1\n",
    "    vocab_size                  = 32\n",
    "    \n",
    "    hidden_height               = 7\n",
    "    hidden_width                = 7\n",
    "\n",
    "    num_blocks                  = 10\n",
    "    n_attn_heads                = 8\n",
    "    hidden_dim                  = 256\n",
    "    dropout_prob                = 0.1\n",
    "\n",
    "    dvae_num_x2upsamples        = 2\n",
    "    dvae_num_resids_downsample  = 3\n",
    "    dvae_num_resids_bottleneck  = 4\n",
    "    dvae_hidden_dim             = 256\n",
    "\n",
    "    load_dvae_path              = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/models/mnist/dvae_vocab32_mnist/\"\n",
    "    dvae_model_name             = \"dvae_vocab32_mnist\"\n",
    "    data_path                   = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/data/MNIST/\"\n",
    "    \n",
    "    NUM_EPOCHS                  = 100\n",
    "    BATCH_SIZE                  = 512\n",
    "    LR                          = 0.01\n",
    "    LR_gamma                    = 0.1\n",
    "    step_LR_milestones          = [5, 15, 25]\n",
    "\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3d4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = torch_transforms.Compose([\n",
    "    torch_transforms.RandomRotation(10),\n",
    "    torch_transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    CONFIG.data_path,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2791761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrEncoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_attn_heads, n_hidden=64, dropout_prob=0.1):\n",
    "        super(TrEncoderBlock, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(n_features, n_attn_heads)\n",
    "        self.ln1 = nn.LayerNorm(n_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_features)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(n_features)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x, pad_mask=None, attn_mask=None):\n",
    "        xn = self.ln1(x)\n",
    "        dx, _ = self.attn(query=xn, key=xn, value=xn, \n",
    "                          key_padding_mask=pad_mask, \n",
    "                          attn_mask=attn_mask)\n",
    "        x = x + self.dropout1(dx)\n",
    "        \n",
    "        xn = self.ln2(x)\n",
    "        dx = self.mlp(xn)\n",
    "        x = x + self.dropout2(dx)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e3fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_width,\n",
    "                 hidden_height,\n",
    "                 embedding_dim,\n",
    "                 num_blocks,\n",
    "                 hidden_dim,\n",
    "                 n_attn_heads,\n",
    "                 dropout_prob):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.hidden_width = hidden_width\n",
    "        self.hidden_height = hidden_height\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.proj_in = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.proj_out = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "        #num_latent_positions = hidden_width * hidden_height\n",
    "        #self.pe = nn.Parameter(torch.randn(num_latent_positions, 1, embedding_dim))\n",
    "        \n",
    "        self.pe_col = nn.Parameter(torch.randn(hidden_width, 1, embedding_dim))\n",
    "        self.pe_row = nn.Parameter(torch.randn(hidden_height, 1, embedding_dim))\n",
    "        \n",
    "        self.tr_encoder_blocks = nn.ModuleList([\n",
    "            TrEncoderBlock(n_features=embedding_dim,\n",
    "                           n_attn_heads=n_attn_heads,\n",
    "                           n_hidden=hidden_dim,\n",
    "                           dropout_prob=dropout_prob)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len, batch, emb = x.size()\n",
    "        mask = subsequent_mask(seq_len).to(x.device)\n",
    "        x = self.proj_in(x)\n",
    "        \n",
    "        pe_column = self.pe_col.repeat(self.hidden_width, 1, 1)\n",
    "        pe_row = self.pe_row.repeat_interleave(self.hidden_height, dim=0)\n",
    "        x = x + pe_column + pe_row\n",
    "        \n",
    "        #x += self.pe\n",
    "        for i, block in enumerate(self.tr_encoder_blocks):\n",
    "            x = block(x, attn_mask=mask)\n",
    "        x = self.proj_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10eb185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = DVAE(\n",
    "    in_channels=CONFIG.img_channels,\n",
    "    vocab_size=CONFIG.vocab_size,\n",
    "    num_x2downsamples=CONFIG.dvae_num_x2upsamples,\n",
    "    num_resids_downsample=CONFIG.dvae_num_resids_downsample,\n",
    "    num_resids_bottleneck=CONFIG.dvae_num_resids_bottleneck,\n",
    "    hidden_dim=CONFIG.dvae_hidden_dim)\n",
    "\n",
    "G = Generator(\n",
    "    hidden_width=CONFIG.hidden_width,\n",
    "    hidden_height=CONFIG.hidden_height,\n",
    "    embedding_dim=CONFIG.vocab_size,\n",
    "    num_blocks=CONFIG.num_blocks,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    n_attn_heads=CONFIG.n_attn_heads,\n",
    "    dropout_prob=CONFIG.dropout_prob)\n",
    "\n",
    "optimizer = optim.Adam(G.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=CONFIG.step_LR_milestones, gamma=CONFIG.LR_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c530d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae.eval()\n",
    "G.train()\n",
    "\n",
    "dvae.load_model(\n",
    "    root_path=CONFIG.load_dvae_path,\n",
    "    model_name=CONFIG.dvae_model_name)\n",
    "\n",
    "dvae.to(CONFIG.DEVICE)\n",
    "G.to(CONFIG.DEVICE)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c661a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "Epoch: 0 Iter: 55 Loss: 2.06154\n",
      "Epoch: 0 Iter: 110 Loss: 1.87343\n",
      "Epoch: 1 Iter: 165 Loss: 1.68171\n",
      "Epoch: 1 Iter: 220 Loss: 1.54566\n",
      "Epoch: 2 Iter: 275 Loss: 1.46942\n",
      "Epoch: 2 Iter: 330 Loss: 1.42948\n",
      "Epoch: 3 Iter: 385 Loss: 1.40426\n",
      "Epoch: 3 Iter: 440 Loss: 1.36992\n",
      "Epoch: 4 Iter: 495 Loss: 1.33171\n",
      "Epoch: 4 Iter: 550 Loss: 1.33682\n",
      "Epoch: 5 Iter: 605 Loss: 1.29554\n",
      "Epoch: 5 Iter: 660 Loss: 1.28585\n",
      "Epoch: 6 Iter: 715 Loss: 1.26996\n",
      "Epoch: 6 Iter: 770 Loss: 1.30226\n",
      "Epoch: 6 Iter: 825 Loss: 1.29658\n",
      "Epoch: 7 Iter: 880 Loss: 1.26322\n",
      "Epoch: 7 Iter: 935 Loss: 1.27975\n",
      "Epoch: 8 Iter: 990 Loss: 1.28984\n",
      "Epoch: 8 Iter: 1045 Loss: 1.27661\n",
      "Epoch: 9 Iter: 1100 Loss: 1.27317\n",
      "Epoch: 9 Iter: 1155 Loss: 1.27771\n",
      "Epoch: 10 Iter: 1210 Loss: 1.26182\n",
      "Epoch: 10 Iter: 1265 Loss: 1.26567\n",
      "Epoch: 11 Iter: 1320 Loss: 1.26368\n",
      "Epoch: 11 Iter: 1375 Loss: 1.24176\n",
      "Epoch: 12 Iter: 1430 Loss: 1.27822\n",
      "Epoch: 12 Iter: 1485 Loss: 1.26951\n",
      "Epoch: 13 Iter: 1540 Loss: 1.26241\n",
      "Epoch: 13 Iter: 1595 Loss: 1.25679\n",
      "Epoch: 13 Iter: 1650 Loss: 1.27301\n",
      "Epoch: 14 Iter: 1705 Loss: 1.25504\n",
      "Epoch: 14 Iter: 1760 Loss: 1.26561\n",
      "Epoch: 15 Iter: 1815 Loss: 1.27973\n",
      "Epoch: 15 Iter: 1870 Loss: 1.23376\n",
      "Epoch: 16 Iter: 1925 Loss: 1.24959\n",
      "Epoch: 16 Iter: 1980 Loss: 1.25779\n",
      "Epoch: 17 Iter: 2035 Loss: 1.25998\n",
      "Epoch: 17 Iter: 2090 Loss: 1.26537\n",
      "Epoch: 18 Iter: 2145 Loss: 1.25906\n",
      "Epoch: 18 Iter: 2200 Loss: 1.25175\n",
      "Epoch: 19 Iter: 2255 Loss: 1.2635\n",
      "Epoch: 19 Iter: 2310 Loss: 1.26485\n",
      "Epoch: 20 Iter: 2365 Loss: 1.23563\n",
      "Epoch: 20 Iter: 2420 Loss: 1.24962\n",
      "Epoch: 20 Iter: 2475 Loss: 1.24877\n",
      "Epoch: 21 Iter: 2530 Loss: 1.25526\n",
      "Epoch: 21 Iter: 2585 Loss: 1.25502\n",
      "Epoch: 22 Iter: 2640 Loss: 1.25039\n",
      "Epoch: 22 Iter: 2695 Loss: 1.24471\n",
      "Epoch: 23 Iter: 2750 Loss: 1.25021\n",
      "Epoch: 23 Iter: 2805 Loss: 1.23049\n",
      "Epoch: 24 Iter: 2860 Loss: 1.24455\n",
      "Epoch: 24 Iter: 2915 Loss: 1.24427\n",
      "Epoch: 25 Iter: 2970 Loss: 1.23052\n",
      "Epoch: 25 Iter: 3025 Loss: 1.23981\n",
      "Epoch: 26 Iter: 3080 Loss: 1.25983\n",
      "Epoch: 26 Iter: 3135 Loss: 1.25537\n",
      "Epoch: 27 Iter: 3190 Loss: 1.258\n",
      "Epoch: 27 Iter: 3245 Loss: 1.25503\n",
      "Epoch: 27 Iter: 3300 Loss: 1.24845\n",
      "Epoch: 28 Iter: 3355 Loss: 1.23692\n",
      "Epoch: 28 Iter: 3410 Loss: 1.24128\n",
      "Epoch: 29 Iter: 3465 Loss: 1.24665\n",
      "Epoch: 29 Iter: 3520 Loss: 1.24717\n",
      "Epoch: 30 Iter: 3575 Loss: 1.25157\n",
      "Epoch: 30 Iter: 3630 Loss: 1.26718\n",
      "Epoch: 31 Iter: 3685 Loss: 1.24366\n",
      "Epoch: 31 Iter: 3740 Loss: 1.23949\n",
      "Epoch: 32 Iter: 3795 Loss: 1.24537\n",
      "Epoch: 32 Iter: 3850 Loss: 1.2587\n",
      "Epoch: 33 Iter: 3905 Loss: 1.24296\n",
      "Epoch: 33 Iter: 3960 Loss: 1.22192\n",
      "Epoch: 34 Iter: 4015 Loss: 1.23939\n",
      "Epoch: 34 Iter: 4070 Loss: 1.23377\n",
      "Epoch: 34 Iter: 4125 Loss: 1.23615\n",
      "Epoch: 35 Iter: 4180 Loss: 1.26217\n",
      "Epoch: 35 Iter: 4235 Loss: 1.23883\n",
      "Epoch: 36 Iter: 4290 Loss: 1.24235\n",
      "Epoch: 36 Iter: 4345 Loss: 1.2346\n",
      "Epoch: 37 Iter: 4400 Loss: 1.25371\n",
      "Epoch: 37 Iter: 4455 Loss: 1.23123\n",
      "Epoch: 38 Iter: 4510 Loss: 1.23787\n",
      "Epoch: 38 Iter: 4565 Loss: 1.24755\n",
      "Epoch: 39 Iter: 4620 Loss: 1.25292\n",
      "Epoch: 39 Iter: 4675 Loss: 1.23387\n",
      "Epoch: 40 Iter: 4730 Loss: 1.25746\n",
      "Epoch: 40 Iter: 4785 Loss: 1.25744\n",
      "Epoch: 41 Iter: 4840 Loss: 1.24664\n",
      "Epoch: 41 Iter: 4895 Loss: 1.25228\n",
      "Epoch: 41 Iter: 4950 Loss: 1.23472\n",
      "Epoch: 42 Iter: 5005 Loss: 1.25639\n",
      "Epoch: 42 Iter: 5060 Loss: 1.26742\n",
      "Epoch: 43 Iter: 5115 Loss: 1.2242\n",
      "Epoch: 43 Iter: 5170 Loss: 1.24721\n",
      "Epoch: 44 Iter: 5225 Loss: 1.23155\n",
      "Epoch: 44 Iter: 5280 Loss: 1.24967\n",
      "Epoch: 45 Iter: 5335 Loss: 1.26054\n",
      "Epoch: 45 Iter: 5390 Loss: 1.24066\n",
      "Epoch: 46 Iter: 5445 Loss: 1.22743\n",
      "Epoch: 46 Iter: 5500 Loss: 1.23721\n",
      "Epoch: 47 Iter: 5555 Loss: 1.23406\n",
      "Epoch: 47 Iter: 5610 Loss: 1.24761\n",
      "Epoch: 48 Iter: 5665 Loss: 1.21492\n",
      "Epoch: 48 Iter: 5720 Loss: 1.22275\n",
      "Epoch: 48 Iter: 5775 Loss: 1.24634\n",
      "Epoch: 49 Iter: 5830 Loss: 1.22641\n",
      "Epoch: 49 Iter: 5885 Loss: 1.26613\n",
      "Epoch: 50 Iter: 5940 Loss: 1.24046\n",
      "Epoch: 50 Iter: 5995 Loss: 1.25346\n",
      "Epoch: 51 Iter: 6050 Loss: 1.26175\n",
      "Epoch: 51 Iter: 6105 Loss: 1.22544\n",
      "Epoch: 52 Iter: 6160 Loss: 1.25365\n",
      "Epoch: 52 Iter: 6215 Loss: 1.23054\n",
      "Epoch: 53 Iter: 6270 Loss: 1.23846\n",
      "Epoch: 53 Iter: 6325 Loss: 1.24512\n",
      "Epoch: 54 Iter: 6380 Loss: 1.22413\n",
      "Epoch: 54 Iter: 6435 Loss: 1.25253\n",
      "Epoch: 54 Iter: 6490 Loss: 1.2602\n",
      "Epoch: 55 Iter: 6545 Loss: 1.25645\n",
      "Epoch: 55 Iter: 6600 Loss: 1.23237\n",
      "Epoch: 56 Iter: 6655 Loss: 1.24815\n",
      "Epoch: 56 Iter: 6710 Loss: 1.25014\n",
      "Epoch: 57 Iter: 6765 Loss: 1.24671\n",
      "Epoch: 57 Iter: 6820 Loss: 1.23701\n",
      "Epoch: 58 Iter: 6875 Loss: 1.24022\n",
      "Epoch: 58 Iter: 6930 Loss: 1.25431\n",
      "Epoch: 59 Iter: 6985 Loss: 1.22729\n",
      "Epoch: 59 Iter: 7040 Loss: 1.23003\n",
      "Epoch: 60 Iter: 7095 Loss: 1.25844\n",
      "Epoch: 60 Iter: 7150 Loss: 1.21896\n",
      "Epoch: 61 Iter: 7205 Loss: 1.23751\n",
      "Epoch: 61 Iter: 7260 Loss: 1.25491\n",
      "Epoch: 61 Iter: 7315 Loss: 1.21943\n",
      "Epoch: 62 Iter: 7370 Loss: 1.2594\n",
      "Epoch: 62 Iter: 7425 Loss: 1.26037\n",
      "Epoch: 63 Iter: 7480 Loss: 1.23051\n",
      "Epoch: 63 Iter: 7535 Loss: 1.25433\n",
      "Epoch: 64 Iter: 7590 Loss: 1.24564\n",
      "Epoch: 64 Iter: 7645 Loss: 1.23981\n",
      "Epoch: 65 Iter: 7700 Loss: 1.25369\n",
      "Epoch: 65 Iter: 7755 Loss: 1.23099\n",
      "Epoch: 66 Iter: 7810 Loss: 1.24303\n",
      "Epoch: 66 Iter: 7865 Loss: 1.24186\n",
      "Epoch: 67 Iter: 7920 Loss: 1.24845\n",
      "Epoch: 67 Iter: 7975 Loss: 1.22946\n",
      "Epoch: 68 Iter: 8030 Loss: 1.23661\n",
      "Epoch: 68 Iter: 8085 Loss: 1.23566\n",
      "Epoch: 68 Iter: 8140 Loss: 1.24015\n",
      "Epoch: 69 Iter: 8195 Loss: 1.23682\n",
      "Epoch: 69 Iter: 8250 Loss: 1.23142\n",
      "Epoch: 70 Iter: 8305 Loss: 1.24471\n",
      "Epoch: 70 Iter: 8360 Loss: 1.23964\n",
      "Epoch: 71 Iter: 8415 Loss: 1.23442\n",
      "Epoch: 71 Iter: 8470 Loss: 1.24345\n",
      "Epoch: 72 Iter: 8525 Loss: 1.23576\n",
      "Epoch: 72 Iter: 8580 Loss: 1.2241\n",
      "Epoch: 73 Iter: 8635 Loss: 1.23613\n",
      "Epoch: 73 Iter: 8690 Loss: 1.23728\n",
      "Epoch: 74 Iter: 8745 Loss: 1.2434\n",
      "Epoch: 74 Iter: 8800 Loss: 1.2321\n",
      "Epoch: 75 Iter: 8855 Loss: 1.24681\n",
      "Epoch: 75 Iter: 8910 Loss: 1.24678\n",
      "Epoch: 75 Iter: 8965 Loss: 1.23871\n",
      "Epoch: 76 Iter: 9020 Loss: 1.24243\n",
      "Epoch: 76 Iter: 9075 Loss: 1.24799\n",
      "Epoch: 77 Iter: 9130 Loss: 1.26324\n",
      "Epoch: 77 Iter: 9185 Loss: 1.24915\n",
      "Epoch: 78 Iter: 9240 Loss: 1.23868\n",
      "Epoch: 78 Iter: 9295 Loss: 1.2403\n",
      "Epoch: 79 Iter: 9350 Loss: 1.27094\n",
      "Epoch: 79 Iter: 9405 Loss: 1.24137\n",
      "Epoch: 80 Iter: 9460 Loss: 1.26055\n",
      "Epoch: 80 Iter: 9515 Loss: 1.25031\n",
      "Epoch: 81 Iter: 9570 Loss: 1.23896\n",
      "Epoch: 81 Iter: 9625 Loss: 1.25925\n",
      "Epoch: 82 Iter: 9680 Loss: 1.2353\n",
      "Epoch: 82 Iter: 9735 Loss: 1.25005\n",
      "Epoch: 82 Iter: 9790 Loss: 1.24553\n",
      "Epoch: 83 Iter: 9845 Loss: 1.24203\n",
      "Epoch: 83 Iter: 9900 Loss: 1.24787\n",
      "Epoch: 84 Iter: 9955 Loss: 1.24392\n",
      "Epoch: 84 Iter: 10010 Loss: 1.23908\n",
      "Epoch: 85 Iter: 10065 Loss: 1.26116\n",
      "Epoch: 85 Iter: 10120 Loss: 1.24496\n",
      "Epoch: 86 Iter: 10175 Loss: 1.23897\n",
      "Epoch: 86 Iter: 10230 Loss: 1.25611\n",
      "Epoch: 87 Iter: 10285 Loss: 1.24356\n",
      "Epoch: 87 Iter: 10340 Loss: 1.23772\n",
      "Epoch: 88 Iter: 10395 Loss: 1.24258\n",
      "Epoch: 88 Iter: 10450 Loss: 1.24457\n",
      "Epoch: 89 Iter: 10505 Loss: 1.2281\n",
      "Epoch: 89 Iter: 10560 Loss: 1.24002\n",
      "Epoch: 89 Iter: 10615 Loss: 1.2596\n",
      "Epoch: 90 Iter: 10670 Loss: 1.23147\n",
      "Epoch: 90 Iter: 10725 Loss: 1.22243\n",
      "Epoch: 91 Iter: 10780 Loss: 1.23761\n",
      "Epoch: 91 Iter: 10835 Loss: 1.23165\n",
      "Epoch: 92 Iter: 10890 Loss: 1.25022\n",
      "Epoch: 92 Iter: 10945 Loss: 1.22859\n",
      "Epoch: 93 Iter: 11000 Loss: 1.22917\n",
      "Epoch: 93 Iter: 11055 Loss: 1.2367\n",
      "Epoch: 94 Iter: 11110 Loss: 1.23817\n",
      "Epoch: 94 Iter: 11165 Loss: 1.24011\n",
      "Epoch: 95 Iter: 11220 Loss: 1.23558\n",
      "Epoch: 95 Iter: 11275 Loss: 1.25456\n",
      "Epoch: 96 Iter: 11330 Loss: 1.24655\n",
      "Epoch: 96 Iter: 11385 Loss: 1.25041\n",
      "Epoch: 96 Iter: 11440 Loss: 1.22429\n",
      "Epoch: 97 Iter: 11495 Loss: 1.24577\n",
      "Epoch: 97 Iter: 11550 Loss: 1.24632\n",
      "Epoch: 98 Iter: 11605 Loss: 1.23607\n",
      "Epoch: 98 Iter: 11660 Loss: 1.24974\n",
      "Epoch: 99 Iter: 11715 Loss: 1.22758\n",
      "Epoch: 99 Iter: 11770 Loss: 1.24775\n"
     ]
    }
   ],
   "source": [
    "print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "criteriation = nn.CrossEntropyLoss()\n",
    "\n",
    "iteration = 0\n",
    "for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "    for img, label in train_loader:\n",
    "        img = img.to(CONFIG.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latent = dvae.ng_q_encode(img)\n",
    "\n",
    "        b, emb, h, w = latent.size()\n",
    "        x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "        start_vector = torch.zeros(1, b, emb, device=x.device)\n",
    "        x_strat_seq = torch.cat([start_vector, x[:-1,:,:]], dim=0)\n",
    "        x_end_seq = x\n",
    "        \n",
    "        output = G(x_strat_seq)\n",
    "        \n",
    "        labels_pred = output.view(-1, emb)\n",
    "        lables_true = x_end_seq.argmax(dim=2).view(-1)\n",
    "        \n",
    "        loss = criteriation(labels_pred, lables_true)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration % 55 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75a47bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width = CONFIG.hidden_width\n",
    "hidden_height = CONFIG.hidden_height\n",
    "seq_len = hidden_width * hidden_height\n",
    "embedding_dim = CONFIG.vocab_size\n",
    "batch_size = 8\n",
    "\n",
    "samples = torch.zeros(seq_len + 1, batch_size, embedding_dim).to(CONFIG.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ff4fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(seq_len):\n",
    "        out = G(samples[:-1,:,:])\n",
    "        \n",
    "        probs = F.softmax(out[i, :, :], dim=-1)\n",
    "\n",
    "        index = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        one_hot_sample = torch.zeros(batch_size, embedding_dim).to(CONFIG.DEVICE)\n",
    "        one_hot_sample = torch.scatter(one_hot_sample, 1, index, 1.0)\n",
    "\n",
    "        samples[i+1, :, :] = one_hot_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f71b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_x = samples[1:, :, :].view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9958ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    gen_img = dvae.decode(latent_x)\n",
    "\n",
    "img_grid = make_grid(gen_img.detach().cpu())\n",
    "show(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8949a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fcdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bff42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84ba24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "707bbaa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def generate_from_part(latent,\n",
    "#                        dvae,\n",
    "#                        hidden_height=7,\n",
    "#                        hidden_width=7,\n",
    "#                        start_seq_len=25,\n",
    "#                        batch_size=8,\n",
    "#                        embedding_dim=32,\n",
    "#                        device=torch.device(\"cuda\")):\n",
    "#     seq_len = hidden_height * hidden_width\n",
    "\n",
    "#     b, emb, h, w = latent.size()\n",
    "#     x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "\n",
    "#     latent_x = torch.empty(seq_len, batch_size, embedding_dim, device=device)\n",
    "\n",
    "#     latent_x[:start_seq_len, :, :] = x[:start_seq_len, :batch_size, :]\n",
    "    \n",
    "#     for i in range(seq_len - start_seq_len):\n",
    "#         with torch.no_grad():\n",
    "#             outputs = G(latent_x[:start_seq_len + i])\n",
    "#         outputs_onehot = ng_quantize(outputs[[-1], :, :], dim=2)\n",
    "#         latent_x[start_seq_len + i] = outputs_onehot\n",
    "\n",
    "#     latent_x = latent_x.view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         gen_img = dvae.ng_q_decode(latent_x)\n",
    "\n",
    "#     img_grid = make_grid(gen_img.detach().cpu())\n",
    "#     show(img_grid)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "# criteriation = nn.CrossEntropyLoss()\n",
    "\n",
    "# iteration = 0\n",
    "# for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "#     for img, label in train_loader:\n",
    "#         img = img.to(CONFIG.DEVICE)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             latent = dvae.ng_q_encode(img)\n",
    "\n",
    "#         b, emb, h, w = latent.size()\n",
    "#         x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "#         x_strat_seq = x[:-1, :, :]\n",
    "#         x_end_seq = x[1:, :, :]\n",
    "        \n",
    "#         output = G(x_strat_seq)\n",
    "        \n",
    "#         labels_pred = output.view(-1, emb)\n",
    "#         lables_true = x_end_seq.argmax(dim=2).view(-1)\n",
    "        \n",
    "#         loss = criteriation(labels_pred, lables_true)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         iteration += 1\n",
    "\n",
    "#         if iteration % 55 == 0:\n",
    "#             print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "    \n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "#         generate_from_part(\n",
    "#             latent=latent,\n",
    "#             dvae=dvae,\n",
    "#             embedding_dim=CONFIG.vocab_size,\n",
    "#             hidden_height=CONFIG.hidden_height,\n",
    "#             hidden_width=CONFIG.hidden_width,\n",
    "#             start_seq_len=25,\n",
    "#             batch_size=8,\n",
    "#             device=CONFIG.DEVICE\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57739bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd180dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be9330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4959210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804bce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29858ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4e6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799ccb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee52c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd9661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34ba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a23de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a7c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77683bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f80ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95e7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fbef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef625d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789406f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535af797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0388c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c1d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39078ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac565d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771bc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd1f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27450f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de53df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab5967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a285620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c86ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc778c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec2c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
