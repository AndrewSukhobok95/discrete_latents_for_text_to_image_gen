{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159420cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as torch_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad6bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../../\")\n",
    "\n",
    "from modules.dvae.model import DVAE\n",
    "from modules.dvae.funcs import ng_quantize\n",
    "from modules.common_blocks import TrDecoderBlock\n",
    "from datasets.mnist_loader import MNISTData\n",
    "from notebooks.utils import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888c7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    img_channels                = 1\n",
    "    vocab_size                  = 32\n",
    "    \n",
    "    hidden_height               = 7\n",
    "    hidden_width                = 7\n",
    "\n",
    "    num_blocks                  = 8\n",
    "    n_attn_heads                = 8\n",
    "    hidden_dim                  = 256\n",
    "    dropout_prob                = 0.1\n",
    "\n",
    "    dvae_num_x2upsamples        = 2\n",
    "    dvae_num_resids_downsample  = 3\n",
    "    dvae_num_resids_bottleneck  = 4\n",
    "    dvae_hidden_dim             = 256\n",
    "\n",
    "    mnist_type                  = \"classic\"\n",
    "    root_img_path               = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/data/MNIST/\"\n",
    "    \n",
    "    load_dvae_path              = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/models/mnist/dvae_vocab32_mnist/\"\n",
    "    dvae_model_name             = \"dvae_vocab32_mnist\"\n",
    "    \n",
    "    model_path                  = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/models/mnist/dtr_ugen_v2_mnist/\"\n",
    "    model_name                  = \"dtr_ugen_v2_mnist\"\n",
    "    \n",
    "    NUM_EPOCHS                  = 30\n",
    "    BATCH_SIZE                  = 512\n",
    "    LR                          = 0.001\n",
    "    LR_gamma                    = 0.1\n",
    "    step_LR_milestones          = [5, 15, 25]\n",
    "\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3d4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = MNISTData(\n",
    "    img_type=CONFIG.mnist_type,\n",
    "    root_path=CONFIG.root_img_path,\n",
    "    batch_size=CONFIG.BATCH_SIZE)\n",
    "train_loader = data_source.get_train_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e3fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_width,\n",
    "                 hidden_height,\n",
    "                 embedding_dim,\n",
    "                 num_blocks,\n",
    "                 hidden_dim,\n",
    "                 n_attn_heads,\n",
    "                 dropout_prob):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.hidden_width = hidden_width\n",
    "        self.hidden_height = hidden_height\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.proj_in = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.proj_out = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "        self.pe_col = nn.Parameter(torch.randn(hidden_width, 1, embedding_dim))\n",
    "        self.pe_row = nn.Parameter(torch.randn(hidden_height, 1, embedding_dim))\n",
    "        \n",
    "        self.tr_dec_blocks = nn.ModuleList([\n",
    "            TrDecoderBlock(\n",
    "                n_features=embedding_dim,\n",
    "                n_attn_heads=n_attn_heads,\n",
    "                n_hidden=hidden_dim,\n",
    "                dropout_prob=dropout_prob)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, noise):\n",
    "        seq_len, batch, emb = x.size()\n",
    "        mask = subsequent_mask(seq_len).to(x.device)\n",
    "        x = self.proj_in(x)\n",
    "        \n",
    "        pe_column = self.pe_col.repeat(self.hidden_width, 1, 1)\n",
    "        pe_row = self.pe_row.repeat_interleave(self.hidden_height, dim=0)\n",
    "        x = x + pe_column + pe_row\n",
    "        \n",
    "        for i, block in enumerate(self.tr_dec_blocks):\n",
    "            x, _, _ = block(x, noise, attn_mask=mask)\n",
    "        \n",
    "        x = self.proj_out(x)\n",
    "        return x\n",
    "    \n",
    "    def save_model(self, root_path, model_name):\n",
    "        if not os.path.exists(root_path):\n",
    "            os.makedirs(root_path)\n",
    "        path = os.path.join(root_path, model_name + \".pth\")\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load_model(self, root_path, model_name, map_location=torch.device('cpu')):\n",
    "        path = os.path.join(root_path, model_name + \".pth\")\n",
    "        self.load_state_dict(torch.load(path, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10eb185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = DVAE(\n",
    "    in_channels=CONFIG.img_channels,\n",
    "    vocab_size=CONFIG.vocab_size,\n",
    "    num_x2downsamples=CONFIG.dvae_num_x2upsamples,\n",
    "    num_resids_downsample=CONFIG.dvae_num_resids_downsample,\n",
    "    num_resids_bottleneck=CONFIG.dvae_num_resids_bottleneck,\n",
    "    hidden_dim=CONFIG.dvae_hidden_dim)\n",
    "\n",
    "G = Generator(\n",
    "    hidden_width=CONFIG.hidden_width,\n",
    "    hidden_height=CONFIG.hidden_height,\n",
    "    embedding_dim=CONFIG.vocab_size,\n",
    "    num_blocks=CONFIG.num_blocks,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    n_attn_heads=CONFIG.n_attn_heads,\n",
    "    dropout_prob=CONFIG.dropout_prob)\n",
    "\n",
    "optimizer = optim.Adam(G.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=CONFIG.step_LR_milestones, gamma=CONFIG.LR_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c530d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae.load_model(\n",
    "    root_path=CONFIG.load_dvae_path,\n",
    "    model_name=CONFIG.dvae_model_name)\n",
    "\n",
    "dvae.eval()\n",
    "G.train()\n",
    "\n",
    "dvae.to(CONFIG.DEVICE)\n",
    "G.to(CONFIG.DEVICE)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c661a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "Epoch: 0 Iter: 55 Loss: 2.24382\n",
      "Epoch: 0 Iter: 110 Loss: 2.11685\n",
      "Epoch: 1 Iter: 165 Loss: 2.02058\n",
      "Epoch: 1 Iter: 220 Loss: 1.92579\n",
      "Epoch: 2 Iter: 275 Loss: 1.87669\n",
      "Epoch: 2 Iter: 330 Loss: 1.78908\n",
      "Epoch: 3 Iter: 385 Loss: 1.7106\n",
      "Epoch: 3 Iter: 440 Loss: 1.63198\n",
      "Epoch: 4 Iter: 495 Loss: 1.60979\n",
      "Epoch: 4 Iter: 550 Loss: 1.55508\n",
      "Epoch: 5 Iter: 605 Loss: 1.52059\n",
      "Epoch: 5 Iter: 660 Loss: 1.51239\n",
      "Epoch: 6 Iter: 715 Loss: 1.4841\n",
      "Epoch: 6 Iter: 770 Loss: 1.47035\n",
      "Epoch: 6 Iter: 825 Loss: 1.45532\n",
      "Epoch: 7 Iter: 880 Loss: 1.45034\n",
      "Epoch: 7 Iter: 935 Loss: 1.43801\n",
      "Epoch: 8 Iter: 990 Loss: 1.41841\n",
      "Epoch: 8 Iter: 1045 Loss: 1.40432\n",
      "Epoch: 9 Iter: 1100 Loss: 1.40048\n",
      "Epoch: 9 Iter: 1155 Loss: 1.41067\n",
      "Epoch: 10 Iter: 1210 Loss: 1.39303\n",
      "Epoch: 10 Iter: 1265 Loss: 1.38382\n",
      "Epoch: 11 Iter: 1320 Loss: 1.39925\n",
      "Epoch: 11 Iter: 1375 Loss: 1.35945\n",
      "Epoch: 12 Iter: 1430 Loss: 1.34689\n",
      "Epoch: 12 Iter: 1485 Loss: 1.37497\n",
      "Epoch: 13 Iter: 1540 Loss: 1.3473\n",
      "Epoch: 13 Iter: 1595 Loss: 1.34929\n",
      "Epoch: 13 Iter: 1650 Loss: 1.35228\n",
      "Epoch: 14 Iter: 1705 Loss: 1.3627\n",
      "Epoch: 14 Iter: 1760 Loss: 1.33875\n",
      "Epoch: 15 Iter: 1815 Loss: 1.34324\n",
      "Epoch: 15 Iter: 1870 Loss: 1.33579\n",
      "Epoch: 16 Iter: 1925 Loss: 1.3339\n",
      "Epoch: 16 Iter: 1980 Loss: 1.32192\n",
      "Epoch: 17 Iter: 2035 Loss: 1.3304\n",
      "Epoch: 17 Iter: 2090 Loss: 1.3188\n",
      "Epoch: 18 Iter: 2145 Loss: 1.30373\n",
      "Epoch: 18 Iter: 2200 Loss: 1.30697\n",
      "Epoch: 19 Iter: 2255 Loss: 1.29786\n",
      "Epoch: 19 Iter: 2310 Loss: 1.29828\n",
      "Epoch: 20 Iter: 2365 Loss: 1.29855\n",
      "Epoch: 20 Iter: 2420 Loss: 1.29126\n",
      "Epoch: 20 Iter: 2475 Loss: 1.30265\n",
      "Epoch: 21 Iter: 2530 Loss: 1.28316\n",
      "Epoch: 21 Iter: 2585 Loss: 1.28719\n",
      "Epoch: 22 Iter: 2640 Loss: 1.27501\n",
      "Epoch: 22 Iter: 2695 Loss: 1.29067\n",
      "Epoch: 23 Iter: 2750 Loss: 1.3207\n",
      "Epoch: 23 Iter: 2805 Loss: 1.31494\n",
      "Epoch: 24 Iter: 2860 Loss: 1.295\n",
      "Epoch: 24 Iter: 2915 Loss: 1.30103\n",
      "Epoch: 25 Iter: 2970 Loss: 1.27521\n",
      "Epoch: 25 Iter: 3025 Loss: 1.27215\n",
      "Epoch: 26 Iter: 3080 Loss: 1.27791\n",
      "Epoch: 26 Iter: 3135 Loss: 1.28001\n",
      "Epoch: 27 Iter: 3190 Loss: 1.25\n",
      "Epoch: 27 Iter: 3245 Loss: 1.2828\n",
      "Epoch: 27 Iter: 3300 Loss: 1.26161\n",
      "Epoch: 28 Iter: 3355 Loss: 1.26104\n",
      "Epoch: 28 Iter: 3410 Loss: 1.25111\n",
      "Epoch: 29 Iter: 3465 Loss: 1.26491\n",
      "Epoch: 29 Iter: 3520 Loss: 1.28639\n"
     ]
    }
   ],
   "source": [
    "print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "criteriation = nn.CrossEntropyLoss()\n",
    "\n",
    "iteration = 0\n",
    "for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "    for img, label in train_loader:\n",
    "        img = img.to(CONFIG.DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            latent = dvae.ng_q_encode(img)\n",
    "            b, emb, h, w = latent.size()\n",
    "            x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "            \n",
    "        noise = torch.randn(1, b, emb, device=CONFIG.DEVICE)\n",
    "        \n",
    "        start_vector = torch.zeros(1, b, emb, device=x.device)\n",
    "        x_strat_seq = torch.cat([start_vector, x[:-1,:,:]], dim=0)\n",
    "        x_end_seq = x\n",
    "        \n",
    "        output = G(x_strat_seq, noise)\n",
    "        \n",
    "        labels_pred = output.view(-1, emb)\n",
    "        lables_true = x_end_seq.argmax(dim=2).view(-1)\n",
    "        \n",
    "        loss = criteriation(labels_pred, lables_true)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration % 55 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "    \n",
    "    #lr_scheduler.step()\n",
    "\n",
    "#G.save_model(CONFIG.model_path, CONFIG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cd8949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_width = CONFIG.hidden_width\n",
    "hidden_height = CONFIG.hidden_height\n",
    "seq_len = hidden_width * hidden_height\n",
    "embedding_dim = CONFIG.vocab_size\n",
    "batch_size = 8\n",
    "\n",
    "samples = torch.zeros(seq_len + 1, batch_size, embedding_dim).to(CONFIG.DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(1, batch_size, embedding_dim, device=CONFIG.DEVICE)\n",
    "    for i in range(seq_len):\n",
    "        out = G(samples[:-1,:,:], noise)\n",
    "        \n",
    "        probs = F.softmax(out[i, :, :], dim=-1)\n",
    "\n",
    "        index = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        one_hot_sample = torch.zeros(batch_size, embedding_dim).to(CONFIG.DEVICE)\n",
    "        one_hot_sample = torch.scatter(one_hot_sample, 1, index, 1.0)\n",
    "        \n",
    "        samples[i+1, :, :] = one_hot_sample\n",
    "\n",
    "latent_x = samples[1:, :, :].view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen_img = dvae.decode(latent_x)\n",
    "\n",
    "img_grid = make_grid(gen_img.detach().cpu())\n",
    "show(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fcdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width = CONFIG.hidden_width\n",
    "hidden_height = CONFIG.hidden_height\n",
    "seq_len = hidden_width * hidden_height\n",
    "embedding_dim = CONFIG.vocab_size\n",
    "batch_size = 8\n",
    "\n",
    "samples = torch.zeros(seq_len + 1, batch_size, embedding_dim).to(CONFIG.DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(1, current_batch_dim, CONFIG.vocab_size, device=CONFIG.DEVICE)\n",
    "    for i in range(seq_len):\n",
    "        out = G(samples[:-1,:,:], noise)\n",
    "        one_hot_sample = ng_quantize(out)\n",
    "        samples[i+1, :, :] = one_hot_sample[i,:,:]\n",
    "\n",
    "latent_x = samples[1:, :, :].view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen_img = dvae.decode(latent_x)\n",
    "\n",
    "img_grid = make_grid(gen_img.detach().cpu())\n",
    "show(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bff42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ad7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2560796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196f72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "707bbaa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def generate_from_part(latent,\n",
    "#                        dvae,\n",
    "#                        hidden_height=7,\n",
    "#                        hidden_width=7,\n",
    "#                        start_seq_len=25,\n",
    "#                        batch_size=8,\n",
    "#                        embedding_dim=32,\n",
    "#                        device=torch.device(\"cuda\")):\n",
    "#     seq_len = hidden_height * hidden_width\n",
    "\n",
    "#     b, emb, h, w = latent.size()\n",
    "#     x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "\n",
    "#     latent_x = torch.empty(seq_len, batch_size, embedding_dim, device=device)\n",
    "\n",
    "#     latent_x[:start_seq_len, :, :] = x[:start_seq_len, :batch_size, :]\n",
    "    \n",
    "#     for i in range(seq_len - start_seq_len):\n",
    "#         with torch.no_grad():\n",
    "#             outputs = G(latent_x[:start_seq_len + i])\n",
    "#         outputs_onehot = ng_quantize(outputs[[-1], :, :], dim=2)\n",
    "#         latent_x[start_seq_len + i] = outputs_onehot\n",
    "\n",
    "#     latent_x = latent_x.view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         gen_img = dvae.ng_q_decode(latent_x)\n",
    "\n",
    "#     img_grid = make_grid(gen_img.detach().cpu())\n",
    "#     show(img_grid)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "# criteriation = nn.CrossEntropyLoss()\n",
    "\n",
    "# iteration = 0\n",
    "# for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "#     for img, label in train_loader:\n",
    "#         img = img.to(CONFIG.DEVICE)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             latent = dvae.ng_q_encode(img)\n",
    "\n",
    "#         b, emb, h, w = latent.size()\n",
    "#         x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "#         x_strat_seq = x[:-1, :, :]\n",
    "#         x_end_seq = x[1:, :, :]\n",
    "        \n",
    "#         output = G(x_strat_seq)\n",
    "        \n",
    "#         labels_pred = output.view(-1, emb)\n",
    "#         lables_true = x_end_seq.argmax(dim=2).view(-1)\n",
    "        \n",
    "#         loss = criteriation(labels_pred, lables_true)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         iteration += 1\n",
    "\n",
    "#         if iteration % 55 == 0:\n",
    "#             print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "    \n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "#         generate_from_part(\n",
    "#             latent=latent,\n",
    "#             dvae=dvae,\n",
    "#             embedding_dim=CONFIG.vocab_size,\n",
    "#             hidden_height=CONFIG.hidden_height,\n",
    "#             hidden_width=CONFIG.hidden_width,\n",
    "#             start_seq_len=25,\n",
    "#             batch_size=8,\n",
    "#             device=CONFIG.DEVICE\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57739bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd180dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be9330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4959210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804bce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29858ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4e6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799ccb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee52c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd9661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34ba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a23de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a7c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77683bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f80ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95e7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fbef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef625d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789406f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535af797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0388c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c1d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39078ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac565d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771bc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd1f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27450f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de53df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab5967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a285620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c86ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc778c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec2c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
