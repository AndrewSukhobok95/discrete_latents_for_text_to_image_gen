{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d44331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../../\")\n",
    "\n",
    "from modules.dvae.model import DVAE\n",
    "from modules.clip.model import CLIP, DVAECLIP\n",
    "from config_reader import ConfigReader\n",
    "from datasets.mnist_loader import MNISTData\n",
    "from utilities.md_mnist_utils import LabelsInfo\n",
    "from notebooks.utils import show\n",
    "from modules.common_utils import latent_to_img, img_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899d96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab44827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6766d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c61102",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = MNISTData(\n",
    "    img_type='md',\n",
    "    root_path='/u/82/sukhoba1/unix/Desktop/TA-VQVAE/data/multi_descriptive_MNIST/',\n",
    "    batch_size=8)\n",
    "\n",
    "train_loader = data_source.get_train_loader(16)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7576d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir_path = '/u/82/sukhoba1/unix/Desktop/TA-VQVAE/configs/finished/'\n",
    "config_path = config_dir_path + 'dvae_mnistmd_v256_ds2_remote.yaml'\n",
    "CONFIG = ConfigReader(config_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7703fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = DVAE(\n",
    "    in_channels=CONFIG.in_channels,\n",
    "    vocab_size=CONFIG.vocab_size,\n",
    "    num_x2downsamples=CONFIG.num_x2downsamples,\n",
    "    num_resids_downsample=CONFIG.num_resids_downsample,\n",
    "    num_resids_bottleneck=CONFIG.num_resids_bottleneck,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    device=CONFIG.DEVICE)\n",
    "\n",
    "dvae.eval()\n",
    "\n",
    "dvae.load_model(\n",
    "    root_path=CONFIG.save_model_path,\n",
    "    model_name=CONFIG.save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4d230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d62425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DVAECLIP(\n",
    "    img_latent_height=32,\n",
    "    img_latent_width=32,\n",
    "    img_latent_channels=256,\n",
    "    txt_max_length=12,\n",
    "    txt_vocab_size=20,\n",
    "    embed_dim=128,\n",
    "    num_blocks=8,\n",
    "    hidden_dim=256,\n",
    "    n_attn_heads=8,\n",
    "    dropout_prob=0.1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06af569a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 0 Loss: 2.94878\n",
      "Epoch: 0 Iter: 20 Loss: 2.77642\n",
      "Epoch: 0 Iter: 40 Loss: 2.77164\n",
      "Epoch: 0 Iter: 60 Loss: 2.77501\n",
      "Epoch: 0 Iter: 80 Loss: 2.77351\n",
      "Epoch: 0 Iter: 100 Loss: 2.7735\n",
      "Epoch: 0 Iter: 120 Loss: 2.76932\n",
      "Epoch: 0 Iter: 140 Loss: 2.77419\n",
      "Epoch: 0 Iter: 160 Loss: 2.77344\n",
      "Epoch: 0 Iter: 180 Loss: 2.77136\n",
      "Epoch: 0 Iter: 200 Loss: 2.772\n",
      "Epoch: 0 Iter: 220 Loss: 2.7686\n",
      "Epoch: 0 Iter: 240 Loss: 2.77069\n",
      "Epoch: 0 Iter: 260 Loss: 2.77297\n",
      "Epoch: 0 Iter: 280 Loss: 2.77108\n",
      "Epoch: 0 Iter: 300 Loss: 2.77227\n",
      "Epoch: 0 Iter: 320 Loss: 2.7742\n",
      "Epoch: 0 Iter: 340 Loss: 2.77213\n",
      "Epoch: 0 Iter: 360 Loss: 2.77284\n",
      "Epoch: 0 Iter: 380 Loss: 2.76459\n",
      "Epoch: 0 Iter: 400 Loss: 2.77479\n",
      "Epoch: 0 Iter: 420 Loss: 2.77291\n",
      "Epoch: 0 Iter: 440 Loss: 2.7727\n",
      "Epoch: 0 Iter: 460 Loss: 2.77273\n",
      "Epoch: 0 Iter: 480 Loss: 2.77226\n",
      "Epoch: 0 Iter: 500 Loss: 2.77224\n",
      "Epoch: 0 Iter: 520 Loss: 2.77198\n",
      "Epoch: 0 Iter: 540 Loss: 2.77324\n",
      "Epoch: 0 Iter: 560 Loss: 2.77291\n",
      "Epoch: 0 Iter: 580 Loss: 2.7729\n",
      "Epoch: 0 Iter: 600 Loss: 2.77282\n",
      "Epoch: 0 Iter: 620 Loss: 2.77266\n",
      "Epoch: 0 Iter: 640 Loss: 2.77241\n",
      "Epoch: 0 Iter: 660 Loss: 2.7723\n",
      "Epoch: 0 Iter: 680 Loss: 2.77228\n",
      "Epoch: 0 Iter: 700 Loss: 2.77311\n",
      "Epoch: 0 Iter: 720 Loss: 2.77226\n",
      "Epoch: 0 Iter: 740 Loss: 2.77283\n",
      "Epoch: 0 Iter: 760 Loss: 2.77302\n",
      "Epoch: 0 Iter: 780 Loss: 2.77297\n",
      "Epoch: 0 Iter: 800 Loss: 2.77241\n",
      "Epoch: 0 Iter: 820 Loss: 2.77218\n",
      "Epoch: 0 Iter: 840 Loss: 2.77309\n",
      "Epoch: 0 Iter: 860 Loss: 2.77225\n",
      "Epoch: 0 Iter: 880 Loss: 2.77241\n",
      "Epoch: 0 Iter: 900 Loss: 2.7733\n",
      "Epoch: 0 Iter: 920 Loss: 2.77268\n",
      "Epoch: 0 Iter: 940 Loss: 2.77179\n",
      "Epoch: 0 Iter: 960 Loss: 2.77211\n",
      "Epoch: 0 Iter: 980 Loss: 2.77239\n",
      "Epoch: 0 Iter: 1000 Loss: 2.77243\n",
      "Epoch: 0 Iter: 1020 Loss: 2.77225\n",
      "Epoch: 0 Iter: 1040 Loss: 2.77185\n",
      "Epoch: 0 Iter: 1060 Loss: 2.77266\n",
      "Epoch: 0 Iter: 1080 Loss: 2.77295\n",
      "Epoch: 0 Iter: 1100 Loss: 2.7732\n",
      "Epoch: 0 Iter: 1120 Loss: 2.77268\n",
      "Epoch: 0 Iter: 1140 Loss: 2.77302\n",
      "Epoch: 0 Iter: 1160 Loss: 2.77308\n",
      "Epoch: 0 Iter: 1180 Loss: 2.77248\n",
      "Epoch: 0 Iter: 1200 Loss: 2.77222\n",
      "Epoch: 0 Iter: 1220 Loss: 2.77242\n",
      "Epoch: 0 Iter: 1240 Loss: 2.77251\n",
      "Epoch: 0 Iter: 1260 Loss: 2.77325\n",
      "Epoch: 0 Iter: 1280 Loss: 2.7726\n",
      "Epoch: 0 Iter: 1300 Loss: 2.77214\n",
      "Epoch: 0 Iter: 1320 Loss: 2.77245\n",
      "Epoch: 0 Iter: 1340 Loss: 2.77318\n",
      "Epoch: 0 Iter: 1360 Loss: 2.77332\n",
      "Epoch: 0 Iter: 1380 Loss: 2.77298\n",
      "Epoch: 0 Iter: 1400 Loss: 2.77263\n",
      "Epoch: 0 Iter: 1420 Loss: 2.77278\n",
      "Epoch: 0 Iter: 1440 Loss: 2.77282\n",
      "Epoch: 0 Iter: 1460 Loss: 2.77213\n",
      "Epoch: 0 Iter: 1480 Loss: 2.77291\n",
      "Epoch: 0 Iter: 1500 Loss: 2.77248\n",
      "Epoch: 0 Iter: 1520 Loss: 2.77296\n",
      "Epoch: 0 Iter: 1540 Loss: 2.77259\n",
      "Epoch: 0 Iter: 1560 Loss: 2.77197\n",
      "Epoch: 0 Iter: 1580 Loss: 2.77196\n",
      "Epoch: 0 Iter: 1600 Loss: 2.77263\n",
      "Epoch: 0 Iter: 1620 Loss: 2.77233\n",
      "Epoch: 0 Iter: 1640 Loss: 2.77283\n",
      "Epoch: 0 Iter: 1660 Loss: 2.77323\n",
      "Epoch: 0 Iter: 1680 Loss: 2.77222\n",
      "Epoch: 0 Iter: 1700 Loss: 2.77281\n",
      "Epoch: 0 Iter: 1720 Loss: 2.77214\n",
      "Epoch: 0 Iter: 1740 Loss: 2.77286\n",
      "Epoch: 0 Iter: 1760 Loss: 2.77275\n",
      "Epoch: 0 Iter: 1780 Loss: 2.77273\n",
      "Epoch: 0 Iter: 1800 Loss: 2.77252\n",
      "Epoch: 0 Iter: 1820 Loss: 2.77175\n",
      "Epoch: 0 Iter: 1840 Loss: 2.77255\n",
      "Epoch: 0 Iter: 1860 Loss: 2.77239\n",
      "Epoch: 0 Iter: 1880 Loss: 2.77308\n",
      "Epoch: 0 Iter: 1900 Loss: 2.77242\n",
      "Epoch: 0 Iter: 1920 Loss: 2.77243\n",
      "Epoch: 0 Iter: 1940 Loss: 2.7728\n",
      "Epoch: 0 Iter: 1960 Loss: 2.77249\n",
      "Epoch: 0 Iter: 1980 Loss: 2.77212\n",
      "Epoch: 0 Iter: 2000 Loss: 2.77236\n",
      "Epoch: 0 Iter: 2020 Loss: 2.77311\n",
      "Epoch: 0 Iter: 2040 Loss: 2.77216\n",
      "Epoch: 0 Iter: 2060 Loss: 2.77279\n",
      "Epoch: 0 Iter: 2080 Loss: 2.77236\n",
      "Epoch: 0 Iter: 2100 Loss: 2.77276\n",
      "Epoch: 0 Iter: 2120 Loss: 2.7723\n",
      "Epoch: 0 Iter: 2140 Loss: 2.77263\n",
      "Epoch: 0 Iter: 2160 Loss: 2.77205\n",
      "Epoch: 0 Iter: 2180 Loss: 2.77239\n",
      "Epoch: 0 Iter: 2200 Loss: 2.77264\n",
      "Epoch: 0 Iter: 2220 Loss: 2.77205\n",
      "Epoch: 0 Iter: 2240 Loss: 2.77241\n",
      "Epoch: 0 Iter: 2260 Loss: 2.77234\n",
      "Epoch: 0 Iter: 2280 Loss: 2.77238\n",
      "Epoch: 0 Iter: 2300 Loss: 2.77293\n",
      "Epoch: 0 Iter: 2320 Loss: 2.7725\n",
      "Epoch: 0 Iter: 2340 Loss: 2.77267\n",
      "Epoch: 0 Iter: 2360 Loss: 2.77171\n",
      "Epoch: 0 Iter: 2380 Loss: 2.77263\n",
      "Epoch: 0 Iter: 2400 Loss: 2.77254\n",
      "Epoch: 0 Iter: 2420 Loss: 2.77212\n",
      "Epoch: 0 Iter: 2440 Loss: 2.77286\n",
      "Epoch: 0 Iter: 2460 Loss: 2.77261\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-71377b3542d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "for epoch in range(100):\n",
    "    for batch_index, (img, txt) in enumerate(train_loader):\n",
    "        current_batch_size = img.size(0)\n",
    "\n",
    "        img = img.to(DEVICE)\n",
    "        txt = txt.permute(1, 0).to(DEVICE)\n",
    "        labels = torch.arange(current_batch_size).to(DEVICE)\n",
    "        \n",
    "        imglat = img_to_latent(img, dvae)\n",
    "        \n",
    "        logits_per_image, logits_per_text = model(imglat, txt)\n",
    "\n",
    "        loss_img = F.cross_entropy(logits_per_image, labels)\n",
    "        loss_txt = F.cross_entropy(logits_per_text, labels)\n",
    "        loss = (loss_img + loss_txt) / 2\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if iteration % 20 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "\n",
    "        if (batch_index + 1) % 4 == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            iteration += 1    \n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eed382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4308f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d192f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fefcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7dad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867bfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIP(\n",
    "    img_height=128,\n",
    "    img_width=128,\n",
    "    img_channels=3,\n",
    "    patch_height=8,\n",
    "    patch_width=8,\n",
    "    txt_max_length=12,\n",
    "    txt_vocab_size=20,\n",
    "    embed_dim=128,\n",
    "    num_blocks=8,\n",
    "    hidden_dim=256,\n",
    "    n_attn_heads=8,\n",
    "    dropout_prob=0.1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7066f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 0 Loss: 4.27204\n",
      "Epoch: 0 Iter: 100 Loss: 3.95311\n",
      "Epoch: 0 Iter: 200 Loss: 3.38472\n",
      "Epoch: 0 Iter: 300 Loss: 2.76777\n",
      "Epoch: 0 Iter: 400 Loss: 1.80431\n",
      "Epoch: 0 Iter: 500 Loss: 0.95452\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a686f28b47a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlogits_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_per_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/modules/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_img, x_txt)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/modules/clip/blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, average_cls_token)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfull_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_encoder_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfull_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maverage_cls_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/modules/common_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, pad_mask, attn_mask)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             dx, _ = self.attn(query=xn, key=xn, value=xn,\n\u001b[0m\u001b[1;32m    123\u001b[0m                               \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                               attn_mask=attn_mask)\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[1;32m    977\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4144\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4145\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4146\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "for epoch in range(100):\n",
    "    for batch_index, (img, txt) in enumerate(train_loader):\n",
    "        current_batch_size = img.size(0)\n",
    "\n",
    "        img = img.to(DEVICE)\n",
    "        txt = txt.permute(1, 0).to(DEVICE)\n",
    "        labels = torch.arange(current_batch_size).to(DEVICE)\n",
    "        \n",
    "        logits_per_image, logits_per_text = model(img, txt)\n",
    "\n",
    "        loss_img = F.cross_entropy(logits_per_image, labels)\n",
    "        loss_txt = F.cross_entropy(logits_per_text, labels)\n",
    "        loss = (loss_img + loss_txt) / 2\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320a2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7601aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dec8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7dbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913386b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c44b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf40f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770140a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, txt = next(iter(train_loader))\n",
    "\n",
    "img = img.to(DEVICE)\n",
    "txt = txt.permute(1, 0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image, logits_per_text = model(img, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(logits_per_image, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(logits_per_text, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae1826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb3969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef18d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f59eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4572d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485dd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b339a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = MNISTData(\n",
    "    img_type='md',\n",
    "    root_path='/u/82/sukhoba1/unix/Desktop/TA-VQVAE/data/multi_descriptive_MNIST/',\n",
    "    batch_size=8)\n",
    "\n",
    "train_loader = data_source.get_train_loader(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99801dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, txt = next(iter(train_loader))\n",
    "\n",
    "img = img.to(DEVICE)\n",
    "txt = txt.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_batch_size = 3\n",
    "\n",
    "img = img.repeat_interleave(current_batch_size, dim=0)\n",
    "txt = txt.repeat(current_batch_size, 1)\n",
    "match_labels = torch.eye(current_batch_size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(img, plot_grid=True, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4238fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63439a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbceb606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f4a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6df4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model = ImgEncoder(\n",
    "    img_height=128,\n",
    "    img_width=128,\n",
    "    img_channels=3,\n",
    "    patch_height=8,\n",
    "    patch_width=8,\n",
    "    embed_dim=128,\n",
    "    num_blocks=8,\n",
    "    hidden_dim=256,\n",
    "    n_attn_heads=8,\n",
    "    dropout_prob=0.1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "txt_model = TxtEncoder(\n",
    "    txt_max_length=12,\n",
    "    txt_vocab_size=20,\n",
    "    embed_dim=128,\n",
    "    num_blocks=8,\n",
    "    hidden_dim=256,\n",
    "    n_attn_heads=8,\n",
    "    dropout_prob=0.1,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_model(txt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c6693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12943a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab7210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd202b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067401a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir_path = '/u/82/sukhoba1/unix/Desktop/TA-VQVAE/configs/'\n",
    "config_path = config_dir_path + 'matcher_mnistmd_v256_ds3.yaml'\n",
    "CONFIG = ConfigReader(config_path=config_path)\n",
    "\n",
    "CONFIG.BATCH_SIZE = 128\n",
    "\n",
    "CONFIG.print_config_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = MNISTData(\n",
    "    img_type=CONFIG.dataset_type,\n",
    "    root_path=CONFIG.root_path,\n",
    "    batch_size=CONFIG.BATCH_SIZE)\n",
    "\n",
    "train_loader = data_source.get_train_loader(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c953d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dvae = DVAE(\n",
    "#     in_channels=CONFIG.in_channels,\n",
    "#     vocab_size=CONFIG.vocab_size,\n",
    "#     num_x2downsamples=CONFIG.num_x2downsamples,\n",
    "#     num_resids_downsample=CONFIG.num_resids_downsample,\n",
    "#     num_resids_bottleneck=CONFIG.num_resids_bottleneck,\n",
    "#     hidden_dim=CONFIG.hidden_dim,\n",
    "#     device=CONFIG.DEVICE)\n",
    "\n",
    "# dvae.eval()\n",
    "# dvae.load_model(\n",
    "#     root_path=CONFIG.vae_model_path,\n",
    "#     model_name=CONFIG.vae_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfdeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrMatcher(\n",
    "    img_height=128,\n",
    "    img_width=128,\n",
    "    img_channels=3,\n",
    "    patch_height=8,\n",
    "    patch_width=8,\n",
    "    txt_max_length=12,\n",
    "    txt_vocab_size=20,\n",
    "    embed_dim=128,\n",
    "    num_blocks=8,\n",
    "    hidden_dim=256,\n",
    "    n_attn_heads=8,\n",
    "    dropout_prob=0.1,\n",
    "    tr_norm_first=False,\n",
    "    out_dim=1,\n",
    "    sigmoid_output=True)\n",
    "\n",
    "# model = TrMatcher(\n",
    "#     img_height=16,\n",
    "#     img_width=16,\n",
    "#     img_embed_dim=CONFIG.vocab_size,\n",
    "#     txt_max_length=12,\n",
    "#     txt_vocab_size=20,\n",
    "#     embed_dim=64,\n",
    "#     num_blocks=8,\n",
    "#     hidden_dim=256,\n",
    "#     n_attn_heads=4,\n",
    "#     dropout_prob=0.1,\n",
    "#     out_dim=1,\n",
    "#     sigmoid_output=True)\n",
    "\n",
    "model.to(CONFIG.DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG.LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723ac00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "    for batch_index, (img, txt) in enumerate(train_loader):\n",
    "        current_batch_size = img.size(0)\n",
    "\n",
    "        img = img.repeat_interleave(current_batch_size, dim=0)\n",
    "        txt = txt.repeat(current_batch_size, 1)\n",
    "        match_labels = torch.eye(current_batch_size).flatten()\n",
    "\n",
    "        img = img.to(CONFIG.DEVICE)\n",
    "        txt = txt.permute(1, 0).to(CONFIG.DEVICE)\n",
    "        match_labels = match_labels.to(CONFIG.DEVICE)\n",
    "\n",
    "        #with torch.no_grad():\n",
    "        #    latent = dvae.ng_q_encode(img)\n",
    "        #b, emb, h, w = latent.size()\n",
    "        #x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "        pred_labels = model(img, txt, average_cls_token=False)\n",
    "\n",
    "        loss = F.binary_cross_entropy(pred_labels, match_labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if iteration % 50 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82463dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2cb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b6a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e76441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71035a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iteration = 0\n",
    "# for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "#     for batch_index, (img, txt) in enumerate(train_loader):\n",
    "#         current_batch_size = img.size(0)\n",
    "#         n_true = current_batch_size // 2\n",
    "#         true_txt = txt[:n_true, :]\n",
    "#         false_txt = txt[n_true:, :]\n",
    "#         false_txt = torch.cat((false_txt[[-1], :], false_txt[:-1, :]), dim=0)\n",
    "#         txt = torch.cat((true_txt, false_txt), dim=0)\n",
    "\n",
    "#         match_labels = torch.zeros(current_batch_size)\n",
    "#         match_labels[:n_true] = 1.0\n",
    "\n",
    "#         img = img.to(CONFIG.DEVICE)\n",
    "#         txt = txt.permute(1, 0).to(CONFIG.DEVICE)\n",
    "#         match_labels = match_labels.to(CONFIG.DEVICE)\n",
    "\n",
    "#         #with torch.no_grad():\n",
    "#         #    latent = dvae.ng_q_encode(img)\n",
    "#         #b, emb, h, w = latent.size()\n",
    "#         #x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "#         pred_labels = model(img, txt)\n",
    "\n",
    "#         loss = F.binary_cross_entropy(pred_labels, match_labels)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         if iteration % 100 == 0:\n",
    "#             print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616857e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c974c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be8e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b0a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, txt = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a34f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_all = img.repeat_interleave(4, dim=0)\n",
    "\n",
    "img_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dee514",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(img_all, plot_grid=True, figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt.repeat(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.eye(4).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e78fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0f38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c902a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf4c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323131d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bca590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c4e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b707b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804eb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_batch_size = img.size(0)\n",
    "n_true = current_batch_size // 2\n",
    "true_txt = txt[:n_true, :]\n",
    "false_txt = txt[n_true:, :]\n",
    "false_txt = torch.cat((false_txt[[-1], :], false_txt[:-1, :]), dim=0)\n",
    "txt_new = torch.cat((true_txt, false_txt), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61311bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad95d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53c4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9027f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bafa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b6195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2ff22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1a919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7c278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690970a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
