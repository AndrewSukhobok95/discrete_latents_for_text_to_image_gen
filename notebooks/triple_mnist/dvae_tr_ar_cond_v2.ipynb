{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159420cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as torch_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad6bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../../\")\n",
    "\n",
    "from modules.dvae.model import DVAE\n",
    "from modules.dvae.funcs import ng_quantize\n",
    "\n",
    "from datasets.triple_mnist import TripleMnistDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "263a51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, figsize=(8, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888c7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "930bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    num_labels                  = 10\n",
    "    \n",
    "    cond_seq_len                = 3\n",
    "    \n",
    "    img_channels                = 1\n",
    "    vocab_size                  = 64\n",
    "    \n",
    "    hidden_height               = 21\n",
    "    hidden_width                = 21\n",
    "\n",
    "    num_blocks                  = 10\n",
    "    n_attn_heads                = 8\n",
    "    hidden_dim                  = 256\n",
    "    dropout_prob                = 0.1\n",
    "\n",
    "    dvae_num_x2upsamples        = 2\n",
    "    dvae_num_resids_downsample  = 3\n",
    "    dvae_num_resids_bottleneck  = 4\n",
    "    dvae_hidden_dim             = 128\n",
    "\n",
    "    data_path                   = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/data/triple_mnist/train\"\n",
    "    \n",
    "    load_dvae_path              = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/models/triple_mnist/dvae_vocab64/\"\n",
    "    dvae_model_name             = \"dvae_vocab64\"\n",
    "    \n",
    "    model_path                  = \"/m/home/home8/82/sukhoba1/data/Desktop/TA-VQVAE/models/triple_mnist/dtr_generator_v2/\"\n",
    "    model_name                  = \"dtr_generator_v2\"\n",
    "    \n",
    "    NUM_EPOCHS                  = 30\n",
    "    BATCH_SIZE                  = 64\n",
    "    LR                          = 0.01\n",
    "    LR_gamma                    = 0.1\n",
    "    step_LR_milestones          = [5, 15, 25]\n",
    "\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a3d4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TripleMnistDataset(\n",
    "    root_img_path=CONFIG.data_path)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2791761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrEncoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_attn_heads, n_hidden=64, dropout_prob=0.1):\n",
    "        super(TrEncoderBlock, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(n_features, n_attn_heads)\n",
    "        self.ln1 = nn.LayerNorm(n_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_features)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(n_features)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x, pad_mask=None, attn_mask=None):\n",
    "        xn = self.ln1(x)\n",
    "        dx, _ = self.attn(query=xn, key=xn, value=xn, \n",
    "                          key_padding_mask=pad_mask, \n",
    "                          attn_mask=attn_mask)\n",
    "        x = x + self.dropout1(dx)\n",
    "        \n",
    "        xn = self.ln2(x)\n",
    "        dx = self.mlp(xn)\n",
    "        x = x + self.dropout2(dx)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac46595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrDecoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_attn_heads, n_hidden=64, dropout_prob=0.1):\n",
    "        super(TrDecoderBlock, self).__init__()\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(n_features, n_attn_heads)\n",
    "        self.ln1 = nn.LayerNorm(n_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(n_features, n_attn_heads)\n",
    "        self.ln2 = nn.LayerNorm(n_features)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_features)\n",
    "        )\n",
    "        self.ln3 = nn.LayerNorm(n_features)\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x, y, pad_mask=None, attn_mask=None):\n",
    "        xn = self.ln1(x)\n",
    "        dx, self_attn_map = self.self_attn(query=xn, key=xn, value=xn, attn_mask=attn_mask)\n",
    "        x = x + self.dropout1(dx)\n",
    "        \n",
    "        xn = self.ln2(x)\n",
    "        dx, cross_attn_map = self.cross_attn(query=xn, key=y, value=y)\n",
    "        x = x + self.dropout2(dx)\n",
    "        \n",
    "        xn = self.ln3(x)\n",
    "        dx = self.mlp(xn)\n",
    "        x = x + self.dropout3(dx)\n",
    "        return x, self_attn_map, cross_attn_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6df0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEmbedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_embeddings,\n",
    "                 embedding_dim,\n",
    "                 seq_len):\n",
    "        super(LabelEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.pe = nn.Parameter(torch.randn(seq_len + 1, 1, embedding_dim))\n",
    "    \n",
    "    def forward(self, label, noise):\n",
    "        emb = self.embedding(label)\n",
    "        emb = emb.permute(1, 0, 2)\n",
    "        y = torch.cat([noise, emb], dim=0)\n",
    "        y = y + self.pe\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87e3fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_width,\n",
    "                 hidden_height,\n",
    "                 embedding_dim,\n",
    "                 num_blocks,\n",
    "                 num_embeddings,\n",
    "                 cond_seq_len,\n",
    "                 hidden_dim,\n",
    "                 n_attn_heads,\n",
    "                 dropout_prob):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.hidden_width = hidden_width\n",
    "        self.hidden_height = hidden_height\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.proj_in = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.proj_out = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "        self.pe_col = nn.Parameter(torch.randn(hidden_width, 1, embedding_dim))\n",
    "        self.pe_row = nn.Parameter(torch.randn(hidden_height, 1, embedding_dim))\n",
    "        \n",
    "        self.tr_blocks = nn.ModuleList([\n",
    "            TrDecoderBlock(\n",
    "                n_features=embedding_dim,\n",
    "                n_attn_heads=n_attn_heads,\n",
    "                n_hidden=hidden_dim,\n",
    "                dropout_prob=dropout_prob)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        self.label_embedding = LabelEmbedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            seq_len=cond_seq_len)\n",
    "\n",
    "    def forward(self, x, label, noise):\n",
    "        seq_len, batch, emb = x.size()\n",
    "        mask = subsequent_mask(seq_len).to(x.device)\n",
    "        x = self.proj_in(x)\n",
    "        \n",
    "        pe_column = self.pe_col.repeat(self.hidden_width, 1, 1)\n",
    "        pe_row = self.pe_row.repeat_interleave(self.hidden_height, dim=0)\n",
    "        x = x + pe_column + pe_row\n",
    "        \n",
    "        y = self.label_embedding(label, noise)\n",
    "        \n",
    "        cross_attn_maps = []\n",
    "        for i, block in enumerate(self.tr_blocks):\n",
    "            x, self_attn_map, cross_attn_map = block(x, y, attn_mask=mask)\n",
    "            cross_attn_maps.append(cross_attn_map)\n",
    "        \n",
    "        x = self.proj_out(x)\n",
    "        return x, cross_attn_maps\n",
    "    \n",
    "    def save_model(self, root_path, model_name):\n",
    "        if not os.path.exists(root_path):\n",
    "            os.makedirs(root_path)\n",
    "        path = os.path.join(root_path, model_name + \".pth\")\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load_model(self, root_path, model_name, map_location=torch.device('cpu')):\n",
    "        path = os.path.join(root_path, model_name + \".pth\")\n",
    "        self.load_state_dict(torch.load(path, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10eb185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = DVAE(\n",
    "    in_channels=CONFIG.img_channels,\n",
    "    vocab_size=CONFIG.vocab_size,\n",
    "    num_x2downsamples=CONFIG.dvae_num_x2upsamples,\n",
    "    num_resids_downsample=CONFIG.dvae_num_resids_downsample,\n",
    "    num_resids_bottleneck=CONFIG.dvae_num_resids_bottleneck,\n",
    "    hidden_dim=CONFIG.dvae_hidden_dim)\n",
    "\n",
    "G = Generator(\n",
    "    hidden_width=CONFIG.hidden_width,\n",
    "    hidden_height=CONFIG.hidden_height,\n",
    "    embedding_dim=CONFIG.vocab_size,\n",
    "    num_blocks=CONFIG.num_blocks,\n",
    "    num_embeddings=CONFIG.num_labels,\n",
    "    cond_seq_len=CONFIG.cond_seq_len,\n",
    "    hidden_dim=CONFIG.hidden_dim,\n",
    "    n_attn_heads=CONFIG.n_attn_heads,\n",
    "    dropout_prob=CONFIG.dropout_prob)\n",
    "\n",
    "optimizer = optim.Adam(G.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=CONFIG.step_LR_milestones, gamma=CONFIG.LR_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c530d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae.eval()\n",
    "G.train()\n",
    "\n",
    "dvae.load_model(\n",
    "    root_path=CONFIG.load_dvae_path,\n",
    "    model_name=CONFIG.dvae_model_name)\n",
    "\n",
    "G.load_model(\n",
    "    root_path=CONFIG.model_path,\n",
    "    model_name=CONFIG.model_name)\n",
    "\n",
    "dvae.to(CONFIG.DEVICE)\n",
    "G.to(CONFIG.DEVICE)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e856e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "Epoch: 0 Iter: 55 Loss: 3.03637\n",
      "Epoch: 0 Iter: 110 Loss: 2.82939\n",
      "Epoch: 0 Iter: 165 Loss: 2.68361\n",
      "Epoch: 0 Iter: 220 Loss: 2.55854\n",
      "Epoch: 0 Iter: 275 Loss: 2.5097\n",
      "Epoch: 0 Iter: 330 Loss: 2.48398\n",
      "Epoch: 0 Iter: 385 Loss: 2.38853\n",
      "Epoch: 0 Iter: 440 Loss: 2.37053\n",
      "Epoch: 0 Iter: 495 Loss: 2.29692\n",
      "Epoch: 0 Iter: 550 Loss: 2.25714\n",
      "Epoch: 0 Iter: 605 Loss: 2.26678\n",
      "Epoch: 0 Iter: 660 Loss: 2.25308\n",
      "Epoch: 0 Iter: 715 Loss: 2.22832\n",
      "Epoch: 0 Iter: 770 Loss: 2.18863\n",
      "Epoch: 0 Iter: 825 Loss: 2.15387\n",
      "Epoch: 0 Iter: 880 Loss: 2.15638\n",
      "Epoch: 0 Iter: 935 Loss: 2.10106\n",
      "Epoch: 0 Iter: 990 Loss: 2.07335\n",
      "Epoch: 0 Iter: 1045 Loss: 2.08686\n",
      "Epoch: 0 Iter: 1100 Loss: 2.05929\n",
      "Epoch: 0 Iter: 1155 Loss: 2.04373\n",
      "Epoch: 0 Iter: 1210 Loss: 2.03117\n",
      "Epoch: 0 Iter: 1265 Loss: 2.02065\n",
      "Epoch: 0 Iter: 1320 Loss: 2.0327\n",
      "Epoch: 0 Iter: 1375 Loss: 2.01963\n",
      "Epoch: 0 Iter: 1430 Loss: 1.99085\n",
      "Epoch: 0 Iter: 1485 Loss: 1.98671\n",
      "Epoch: 0 Iter: 1540 Loss: 1.97716\n",
      "Epoch: 0 Iter: 1595 Loss: 1.99259\n",
      "Epoch: 0 Iter: 1650 Loss: 1.96449\n",
      "Epoch: 0 Iter: 1705 Loss: 1.98892\n",
      "Epoch: 0 Iter: 1760 Loss: 1.967\n",
      "Epoch: 0 Iter: 1815 Loss: 1.95063\n",
      "Epoch: 0 Iter: 1870 Loss: 1.95301\n",
      "Epoch: 0 Iter: 1925 Loss: 1.94783\n",
      "Epoch: 0 Iter: 1980 Loss: 1.93577\n",
      "Epoch: 0 Iter: 2035 Loss: 1.92382\n",
      "Epoch: 0 Iter: 2090 Loss: 1.95637\n",
      "Epoch: 0 Iter: 2145 Loss: 1.94041\n",
      "Epoch: 0 Iter: 2200 Loss: 1.93047\n",
      "Epoch: 0 Iter: 2255 Loss: 1.89808\n",
      "Epoch: 0 Iter: 2310 Loss: 1.94028\n",
      "Epoch: 0 Iter: 2365 Loss: 1.91385\n",
      "Epoch: 0 Iter: 2420 Loss: 1.91429\n",
      "Epoch: 0 Iter: 2475 Loss: 1.8982\n",
      "Epoch: 0 Iter: 2530 Loss: 1.91588\n",
      "Epoch: 0 Iter: 2585 Loss: 1.9014\n",
      "Epoch: 0 Iter: 2640 Loss: 1.88971\n",
      "Epoch: 0 Iter: 2695 Loss: 1.91\n",
      "Epoch: 0 Iter: 2750 Loss: 1.89865\n",
      "Epoch: 0 Iter: 2805 Loss: 1.88577\n",
      "Epoch: 0 Iter: 2860 Loss: 1.91676\n",
      "Epoch: 0 Iter: 2915 Loss: 1.86915\n",
      "Epoch: 0 Iter: 2970 Loss: 1.8748\n",
      "Epoch: 0 Iter: 3025 Loss: 1.88255\n",
      "Epoch: 0 Iter: 3080 Loss: 1.8789\n",
      "Epoch: 0 Iter: 3135 Loss: 1.84378\n",
      "Epoch: 0 Iter: 3190 Loss: 1.86685\n",
      "Epoch: 0 Iter: 3245 Loss: 1.88211\n",
      "Epoch: 0 Iter: 3300 Loss: 1.9117\n",
      "Epoch: 0 Iter: 3355 Loss: 1.8732\n",
      "Epoch: 0 Iter: 3410 Loss: 1.87236\n",
      "Epoch: 0 Iter: 3465 Loss: 1.89098\n",
      "Epoch: 0 Iter: 3520 Loss: 1.85061\n",
      "Epoch: 0 Iter: 3575 Loss: 1.88281\n",
      "Epoch: 0 Iter: 3630 Loss: 1.882\n",
      "Epoch: 0 Iter: 3685 Loss: 1.85531\n",
      "Epoch: 0 Iter: 3740 Loss: 1.87455\n",
      "Epoch: 0 Iter: 3795 Loss: 1.88465\n",
      "Epoch: 0 Iter: 3850 Loss: 1.85411\n",
      "Epoch: 0 Iter: 3905 Loss: 1.87816\n",
      "Epoch: 0 Iter: 3960 Loss: 1.87433\n",
      "Epoch: 0 Iter: 4015 Loss: 1.86747\n",
      "Epoch: 0 Iter: 4070 Loss: 1.86612\n",
      "Epoch: 0 Iter: 4125 Loss: 1.88298\n",
      "Epoch: 0 Iter: 4180 Loss: 1.86872\n",
      "Epoch: 0 Iter: 4235 Loss: 1.86252\n",
      "Epoch: 0 Iter: 4290 Loss: 1.86202\n",
      "Epoch: 0 Iter: 4345 Loss: 1.84515\n",
      "Epoch: 0 Iter: 4400 Loss: 1.85429\n",
      "Epoch: 0 Iter: 4455 Loss: 1.86237\n",
      "Epoch: 0 Iter: 4510 Loss: 1.83085\n",
      "Epoch: 0 Iter: 4565 Loss: 1.87185\n",
      "Epoch: 0 Iter: 4620 Loss: 1.88119\n",
      "Epoch: 0 Iter: 4675 Loss: 1.87828\n",
      "Epoch: 0 Iter: 4730 Loss: 1.85275\n",
      "Epoch: 0 Iter: 4785 Loss: 1.86314\n",
      "Epoch: 0 Iter: 4840 Loss: 1.85595\n",
      "Epoch: 0 Iter: 4895 Loss: 1.84247\n",
      "Epoch: 0 Iter: 4950 Loss: 1.86122\n",
      "Epoch: 0 Iter: 5005 Loss: 1.84681\n",
      "Epoch: 0 Iter: 5060 Loss: 1.87483\n",
      "Epoch: 0 Iter: 5115 Loss: 1.85442\n",
      "Epoch: 0 Iter: 5170 Loss: 1.86268\n",
      "Epoch: 0 Iter: 5225 Loss: 1.8428\n",
      "Epoch: 0 Iter: 5280 Loss: 1.82183\n",
      "Epoch: 0 Iter: 5335 Loss: 1.84352\n",
      "Epoch: 0 Iter: 5390 Loss: 1.84625\n",
      "Epoch: 0 Iter: 5445 Loss: 1.86252\n",
      "Epoch: 0 Iter: 5500 Loss: 1.84033\n",
      "Epoch: 0 Iter: 5555 Loss: 1.87157\n",
      "Epoch: 0 Iter: 5610 Loss: 1.83416\n",
      "Epoch: 0 Iter: 5665 Loss: 1.86141\n",
      "Epoch: 0 Iter: 5720 Loss: 1.85373\n",
      "Epoch: 0 Iter: 5775 Loss: 1.8428\n",
      "Epoch: 0 Iter: 5830 Loss: 1.85394\n",
      "Epoch: 0 Iter: 5885 Loss: 1.87763\n",
      "Epoch: 0 Iter: 5940 Loss: 1.84679\n",
      "Epoch: 0 Iter: 5995 Loss: 1.87194\n",
      "Epoch: 0 Iter: 6050 Loss: 1.82312\n",
      "Epoch: 0 Iter: 6105 Loss: 1.84199\n",
      "Epoch: 0 Iter: 6160 Loss: 1.8625\n",
      "Epoch: 0 Iter: 6215 Loss: 1.84347\n",
      "Epoch: 0 Iter: 6270 Loss: 1.84267\n",
      "Epoch: 0 Iter: 6325 Loss: 1.85144\n",
      "Epoch: 0 Iter: 6380 Loss: 1.84626\n",
      "Epoch: 0 Iter: 6435 Loss: 1.81017\n",
      "Epoch: 0 Iter: 6490 Loss: 1.83061\n",
      "Epoch: 0 Iter: 6545 Loss: 1.85377\n",
      "Epoch: 0 Iter: 6600 Loss: 1.87347\n",
      "Epoch: 0 Iter: 6655 Loss: 1.83794\n",
      "Epoch: 0 Iter: 6710 Loss: 1.85198\n",
      "Epoch: 0 Iter: 6765 Loss: 1.83742\n",
      "Epoch: 0 Iter: 6820 Loss: 1.83988\n",
      "Epoch: 0 Iter: 6875 Loss: 1.83151\n",
      "Epoch: 0 Iter: 6930 Loss: 1.81713\n",
      "Epoch: 0 Iter: 6985 Loss: 1.82385\n",
      "Epoch: 0 Iter: 7040 Loss: 1.81897\n",
      "Epoch: 0 Iter: 7095 Loss: 1.81794\n",
      "Epoch: 0 Iter: 7150 Loss: 1.83556\n",
      "Epoch: 0 Iter: 7205 Loss: 1.84409\n",
      "Epoch: 0 Iter: 7260 Loss: 1.83388\n",
      "Epoch: 0 Iter: 7315 Loss: 1.84054\n",
      "Epoch: 0 Iter: 7370 Loss: 1.81489\n",
      "Epoch: 0 Iter: 7425 Loss: 1.81296\n",
      "Epoch: 0 Iter: 7480 Loss: 1.80133\n",
      "Epoch: 0 Iter: 7535 Loss: 1.80362\n",
      "Epoch: 0 Iter: 7590 Loss: 1.80285\n",
      "Epoch: 0 Iter: 7645 Loss: 1.82077\n",
      "Epoch: 0 Iter: 7700 Loss: 1.81428\n",
      "Epoch: 0 Iter: 7755 Loss: 1.80266\n",
      "Epoch: 0 Iter: 7810 Loss: 1.81094\n",
      "Epoch: 0 Iter: 7865 Loss: 1.84043\n",
      "Epoch: 0 Iter: 7920 Loss: 1.8456\n",
      "Epoch: 0 Iter: 7975 Loss: 1.8193\n",
      "Epoch: 0 Iter: 8030 Loss: 1.82377\n",
      "Epoch: 0 Iter: 8085 Loss: 1.84686\n",
      "Epoch: 0 Iter: 8140 Loss: 1.83354\n",
      "Epoch: 0 Iter: 8195 Loss: 1.83439\n",
      "Epoch: 0 Iter: 8250 Loss: 1.82703\n",
      "Epoch: 0 Iter: 8305 Loss: 1.84093\n",
      "Epoch: 0 Iter: 8360 Loss: 1.77688\n",
      "Epoch: 0 Iter: 8415 Loss: 1.81424\n",
      "Epoch: 0 Iter: 8470 Loss: 1.80394\n",
      "Epoch: 0 Iter: 8525 Loss: 1.83462\n",
      "Epoch: 0 Iter: 8580 Loss: 1.81117\n",
      "Epoch: 0 Iter: 8635 Loss: 1.8094\n",
      "Epoch: 0 Iter: 8690 Loss: 1.83634\n",
      "Epoch: 0 Iter: 8745 Loss: 1.80756\n",
      "Epoch: 0 Iter: 8800 Loss: 1.83899\n",
      "Epoch: 0 Iter: 8855 Loss: 1.82817\n",
      "Epoch: 0 Iter: 8910 Loss: 1.81856\n",
      "Epoch: 0 Iter: 8965 Loss: 1.80988\n",
      "Epoch: 0 Iter: 9020 Loss: 1.86014\n",
      "Epoch: 0 Iter: 9075 Loss: 1.83237\n",
      "Epoch: 0 Iter: 9130 Loss: 1.82069\n",
      "Epoch: 0 Iter: 9185 Loss: 1.82069\n",
      "Epoch: 0 Iter: 9240 Loss: 1.82851\n",
      "Epoch: 0 Iter: 9295 Loss: 1.81234\n",
      "Epoch: 0 Iter: 9350 Loss: 1.81819\n",
      "Epoch: 0 Iter: 9405 Loss: 1.80864\n",
      "Epoch: 0 Iter: 9460 Loss: 1.78644\n",
      "Epoch: 0 Iter: 9515 Loss: 1.83177\n",
      "Epoch: 0 Iter: 9570 Loss: 1.82798\n",
      "Epoch: 0 Iter: 9625 Loss: 1.81763\n",
      "Epoch: 0 Iter: 9680 Loss: 1.81266\n",
      "Epoch: 0 Iter: 9735 Loss: 1.83887\n",
      "Epoch: 0 Iter: 9790 Loss: 1.83173\n",
      "Epoch: 0 Iter: 9845 Loss: 1.83232\n",
      "Epoch: 0 Iter: 9900 Loss: 1.79566\n",
      "Epoch: 0 Iter: 9955 Loss: 1.81601\n",
      "Epoch: 1 Iter: 10010 Loss: 1.8155\n",
      "Epoch: 1 Iter: 10065 Loss: 1.79873\n",
      "Epoch: 1 Iter: 10120 Loss: 1.79518\n",
      "Epoch: 1 Iter: 10175 Loss: 1.8069\n",
      "Epoch: 1 Iter: 10230 Loss: 1.80763\n",
      "Epoch: 1 Iter: 10285 Loss: 1.81655\n",
      "Epoch: 1 Iter: 10340 Loss: 1.812\n",
      "Epoch: 1 Iter: 10395 Loss: 1.79781\n",
      "Epoch: 1 Iter: 10450 Loss: 1.79304\n",
      "Epoch: 1 Iter: 10505 Loss: 1.82441\n",
      "Epoch: 1 Iter: 10560 Loss: 1.8096\n",
      "Epoch: 1 Iter: 10615 Loss: 1.81066\n",
      "Epoch: 1 Iter: 10670 Loss: 1.79528\n",
      "Epoch: 1 Iter: 10725 Loss: 1.81169\n",
      "Epoch: 1 Iter: 10780 Loss: 1.80291\n",
      "Epoch: 1 Iter: 10835 Loss: 1.81141\n",
      "Epoch: 1 Iter: 10890 Loss: 1.8305\n",
      "Epoch: 1 Iter: 10945 Loss: 1.8165\n",
      "Epoch: 1 Iter: 11000 Loss: 1.79512\n",
      "Epoch: 1 Iter: 11055 Loss: 1.80873\n",
      "Epoch: 1 Iter: 11110 Loss: 1.80259\n",
      "Epoch: 1 Iter: 11165 Loss: 1.80584\n",
      "Epoch: 1 Iter: 11220 Loss: 1.79313\n",
      "Epoch: 1 Iter: 11275 Loss: 1.82218\n",
      "Epoch: 1 Iter: 11330 Loss: 1.79402\n",
      "Epoch: 1 Iter: 11385 Loss: 1.80368\n",
      "Epoch: 1 Iter: 11440 Loss: 1.80444\n",
      "Epoch: 1 Iter: 11495 Loss: 1.78957\n",
      "Epoch: 1 Iter: 11550 Loss: 1.78515\n",
      "Epoch: 1 Iter: 11605 Loss: 1.82191\n",
      "Epoch: 1 Iter: 11660 Loss: 1.82532\n",
      "Epoch: 1 Iter: 11715 Loss: 1.78872\n",
      "Epoch: 1 Iter: 11770 Loss: 1.79538\n",
      "Epoch: 1 Iter: 11825 Loss: 1.7988\n",
      "Epoch: 1 Iter: 11880 Loss: 1.81449\n",
      "Epoch: 1 Iter: 11935 Loss: 1.79128\n",
      "Epoch: 1 Iter: 11990 Loss: 1.7934\n",
      "Epoch: 1 Iter: 12045 Loss: 1.80795\n",
      "Epoch: 1 Iter: 12100 Loss: 1.812\n",
      "Epoch: 1 Iter: 12155 Loss: 1.78484\n",
      "Epoch: 1 Iter: 12210 Loss: 1.79957\n",
      "Epoch: 1 Iter: 12265 Loss: 1.78738\n",
      "Epoch: 1 Iter: 12320 Loss: 1.79058\n",
      "Epoch: 1 Iter: 12375 Loss: 1.79539\n",
      "Epoch: 1 Iter: 12430 Loss: 1.8037\n",
      "Epoch: 1 Iter: 12485 Loss: 1.77046\n",
      "Epoch: 1 Iter: 12540 Loss: 1.79845\n",
      "Epoch: 1 Iter: 12595 Loss: 1.80059\n",
      "Epoch: 1 Iter: 12650 Loss: 1.80244\n",
      "Epoch: 1 Iter: 12705 Loss: 1.78723\n",
      "Epoch: 1 Iter: 12760 Loss: 1.80289\n",
      "Epoch: 1 Iter: 12815 Loss: 1.79258\n",
      "Epoch: 1 Iter: 12870 Loss: 1.79103\n",
      "Epoch: 1 Iter: 12925 Loss: 1.80348\n",
      "Epoch: 1 Iter: 12980 Loss: 1.77815\n",
      "Epoch: 1 Iter: 13035 Loss: 1.79411\n",
      "Epoch: 1 Iter: 13090 Loss: 1.81512\n",
      "Epoch: 1 Iter: 13145 Loss: 1.80875\n",
      "Epoch: 1 Iter: 13200 Loss: 1.81139\n",
      "Epoch: 1 Iter: 13255 Loss: 1.78449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iter: 13310 Loss: 1.77662\n",
      "Epoch: 1 Iter: 13365 Loss: 1.82612\n",
      "Epoch: 1 Iter: 13420 Loss: 1.79843\n",
      "Epoch: 1 Iter: 13475 Loss: 1.80468\n",
      "Epoch: 1 Iter: 13530 Loss: 1.80906\n",
      "Epoch: 1 Iter: 13585 Loss: 1.80541\n",
      "Epoch: 1 Iter: 13640 Loss: 1.7956\n",
      "Epoch: 1 Iter: 13695 Loss: 1.81128\n",
      "Epoch: 1 Iter: 13750 Loss: 1.80755\n",
      "Epoch: 1 Iter: 13805 Loss: 1.76565\n",
      "Epoch: 1 Iter: 13860 Loss: 1.76934\n",
      "Epoch: 1 Iter: 13915 Loss: 1.81871\n",
      "Epoch: 1 Iter: 13970 Loss: 1.83708\n",
      "Epoch: 1 Iter: 14025 Loss: 1.78807\n",
      "Epoch: 1 Iter: 14080 Loss: 1.81412\n",
      "Epoch: 1 Iter: 14135 Loss: 1.78638\n",
      "Epoch: 1 Iter: 14190 Loss: 1.80157\n",
      "Epoch: 1 Iter: 14245 Loss: 1.79226\n",
      "Epoch: 1 Iter: 14300 Loss: 1.79354\n",
      "Epoch: 1 Iter: 14355 Loss: 1.7824\n",
      "Epoch: 1 Iter: 14410 Loss: 1.77959\n",
      "Epoch: 1 Iter: 14465 Loss: 1.78821\n",
      "Epoch: 1 Iter: 14520 Loss: 1.77824\n",
      "Epoch: 1 Iter: 14575 Loss: 1.79533\n",
      "Epoch: 1 Iter: 14630 Loss: 1.80296\n",
      "Epoch: 1 Iter: 14685 Loss: 1.79172\n",
      "Epoch: 1 Iter: 14740 Loss: 1.79758\n",
      "Epoch: 1 Iter: 14795 Loss: 1.79045\n",
      "Epoch: 1 Iter: 14850 Loss: 1.81253\n",
      "Epoch: 1 Iter: 14905 Loss: 1.81826\n",
      "Epoch: 1 Iter: 14960 Loss: 1.81287\n",
      "Epoch: 1 Iter: 15015 Loss: 1.78057\n",
      "Epoch: 1 Iter: 15070 Loss: 1.80144\n",
      "Epoch: 1 Iter: 15125 Loss: 1.80642\n",
      "Epoch: 1 Iter: 15180 Loss: 1.79521\n",
      "Epoch: 1 Iter: 15235 Loss: 1.80957\n",
      "Epoch: 1 Iter: 15290 Loss: 1.79412\n",
      "Epoch: 1 Iter: 15345 Loss: 1.83159\n",
      "Epoch: 1 Iter: 15400 Loss: 1.79832\n",
      "Epoch: 1 Iter: 15455 Loss: 1.78457\n",
      "Epoch: 1 Iter: 15510 Loss: 1.79654\n",
      "Epoch: 1 Iter: 15565 Loss: 1.78282\n",
      "Epoch: 1 Iter: 15620 Loss: 1.76313\n",
      "Epoch: 1 Iter: 15675 Loss: 1.78547\n",
      "Epoch: 1 Iter: 15730 Loss: 1.79435\n",
      "Epoch: 1 Iter: 15785 Loss: 1.79136\n",
      "Epoch: 1 Iter: 15840 Loss: 1.79302\n",
      "Epoch: 1 Iter: 15895 Loss: 1.80047\n",
      "Epoch: 1 Iter: 15950 Loss: 1.7999\n",
      "Epoch: 1 Iter: 16005 Loss: 1.78186\n",
      "Epoch: 1 Iter: 16060 Loss: 1.80304\n",
      "Epoch: 1 Iter: 16115 Loss: 1.78502\n",
      "Epoch: 1 Iter: 16170 Loss: 1.77032\n",
      "Epoch: 1 Iter: 16225 Loss: 1.79741\n",
      "Epoch: 1 Iter: 16280 Loss: 1.78203\n",
      "Epoch: 1 Iter: 16335 Loss: 1.78706\n",
      "Epoch: 1 Iter: 16390 Loss: 1.80469\n",
      "Epoch: 1 Iter: 16445 Loss: 1.79782\n",
      "Epoch: 1 Iter: 16500 Loss: 1.79112\n",
      "Epoch: 1 Iter: 16555 Loss: 1.7873\n",
      "Epoch: 1 Iter: 16610 Loss: 1.81232\n",
      "Epoch: 1 Iter: 16665 Loss: 1.77625\n",
      "Epoch: 1 Iter: 16720 Loss: 1.79014\n",
      "Epoch: 1 Iter: 16775 Loss: 1.78725\n",
      "Epoch: 1 Iter: 16830 Loss: 1.7788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-21c398d7d022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tavqvae/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Device in use: {}\".format(CONFIG.DEVICE))\n",
    "\n",
    "criteriation = nn.CrossEntropyLoss()\n",
    "\n",
    "iteration = 0\n",
    "for epoch in range(CONFIG.NUM_EPOCHS):\n",
    "    for img, label in train_loader:\n",
    "        label = label.to(CONFIG.DEVICE)\n",
    "        img = img.to(CONFIG.DEVICE)\n",
    "        \n",
    "        current_batch_dim = img.size(0)\n",
    "        noise = torch.randn(1, current_batch_dim, CONFIG.vocab_size, device=CONFIG.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latent = dvae.ng_q_encode(img)\n",
    "\n",
    "        b, emb, h, w = latent.size()\n",
    "        x = latent.view(b, emb, -1).permute(2, 0, 1)\n",
    "        \n",
    "        start_vector = torch.zeros(1, b, emb, device=x.device)\n",
    "        x_strat_seq = torch.cat([start_vector, x[:-1,:,:]], dim=0)\n",
    "        x_end_seq = x\n",
    "        \n",
    "        output, attn_maps = G(x_strat_seq, label, noise)\n",
    "        \n",
    "        seq_labels_pred = output.view(-1, emb)\n",
    "        seq_lables_true = x_end_seq.argmax(dim=2).view(-1)\n",
    "        \n",
    "        loss = criteriation(seq_labels_pred, seq_lables_true)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration % 55 == 0:\n",
    "            print(\"Epoch: {} Iter: {} Loss: {}\".format(epoch, iteration, round(loss.item(), 5)))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9420a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save_model(CONFIG.model_path, CONFIG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72396775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_width = CONFIG.hidden_width\n",
    "hidden_height = CONFIG.hidden_height\n",
    "seq_len = hidden_width * hidden_height\n",
    "embedding_dim = CONFIG.vocab_size\n",
    "batch_size = 8\n",
    "\n",
    "samples = torch.zeros(seq_len + 1, batch_size, embedding_dim).to(CONFIG.DEVICE)\n",
    "\n",
    "sample_labels = torch.LongTensor([\n",
    "    [0,0,2],\n",
    "    [0,0,2],\n",
    "    [0,0,2],\n",
    "    [0,0,2],\n",
    "    [0,1,2],\n",
    "    [0,1,2],\n",
    "    [0,1,2],\n",
    "    [0,1,2]\n",
    "]).to(CONFIG.DEVICE)\n",
    "\n",
    "sample_noise = torch.randn(1, batch_size, CONFIG.vocab_size, device=CONFIG.DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(seq_len):\n",
    "        out, cross_attn_maps = G(samples[:-1,:,:], sample_labels, sample_noise)\n",
    "        \n",
    "        z = ng_quantize(out, dim=-1)\n",
    "        one_hot_sample = z[i,:,:]\n",
    "\n",
    "        samples[i+1, :, :] = one_hot_sample\n",
    "\n",
    "latent_x = samples[1:, :, :].view(hidden_height, hidden_width, batch_size, embedding_dim).permute(2, 3, 0, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen_img = dvae.decode(latent_x)\n",
    "\n",
    "img_grid = make_grid(gen_img.detach().cpu())\n",
    "show(img_grid, figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92341f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d98f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f820d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb6ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d41fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b623d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc82be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b68b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_map = cross_attn_maps[-1]\n",
    "token_block_map = block_map[12, :, 1].view(hidden_height, hidden_width)\n",
    "\n",
    "pltheatmap = token_block_map.detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(pltheatmap, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1165f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6306f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d902b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5b3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac50eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3de51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb8455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
